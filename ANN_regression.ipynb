{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bike sharing dataset\n",
    "source:-https://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.344167</td>\n",
       "      <td>0.363625</td>\n",
       "      <td>0.805833</td>\n",
       "      <td>0.160446</td>\n",
       "      <td>331</td>\n",
       "      <td>654</td>\n",
       "      <td>985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2011-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.363478</td>\n",
       "      <td>0.353739</td>\n",
       "      <td>0.696087</td>\n",
       "      <td>0.248539</td>\n",
       "      <td>131</td>\n",
       "      <td>670</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2011-01-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.196364</td>\n",
       "      <td>0.189405</td>\n",
       "      <td>0.437273</td>\n",
       "      <td>0.248309</td>\n",
       "      <td>120</td>\n",
       "      <td>1229</td>\n",
       "      <td>1349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2011-01-04</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.212122</td>\n",
       "      <td>0.590435</td>\n",
       "      <td>0.160296</td>\n",
       "      <td>108</td>\n",
       "      <td>1454</td>\n",
       "      <td>1562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-01-05</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.226957</td>\n",
       "      <td>0.229270</td>\n",
       "      <td>0.436957</td>\n",
       "      <td>0.186900</td>\n",
       "      <td>82</td>\n",
       "      <td>1518</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instant      dteday  season  yr  mnth  holiday  weekday  workingday  \\\n",
       "0        1  2011-01-01       1   0     1        0        6           0   \n",
       "1        2  2011-01-02       1   0     1        0        0           0   \n",
       "2        3  2011-01-03       1   0     1        0        1           1   \n",
       "3        4  2011-01-04       1   0     1        0        2           1   \n",
       "4        5  2011-01-05       1   0     1        0        3           1   \n",
       "\n",
       "   weathersit      temp     atemp       hum  windspeed  casual  registered  \\\n",
       "0           2  0.344167  0.363625  0.805833   0.160446     331         654   \n",
       "1           2  0.363478  0.353739  0.696087   0.248539     131         670   \n",
       "2           1  0.196364  0.189405  0.437273   0.248309     120        1229   \n",
       "3           1  0.200000  0.212122  0.590435   0.160296     108        1454   \n",
       "4           1  0.226957  0.229270  0.436957   0.186900      82        1518   \n",
       "\n",
       "    cnt  \n",
       "0   985  \n",
       "1   801  \n",
       "2  1349  \n",
       "3  1562  \n",
       "4  1600  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"day.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 731 entries, 0 to 730\n",
      "Data columns (total 16 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   instant     731 non-null    int64  \n",
      " 1   dteday      731 non-null    object \n",
      " 2   season      731 non-null    int64  \n",
      " 3   yr          731 non-null    int64  \n",
      " 4   mnth        731 non-null    int64  \n",
      " 5   holiday     731 non-null    int64  \n",
      " 6   weekday     731 non-null    int64  \n",
      " 7   workingday  731 non-null    int64  \n",
      " 8   weathersit  731 non-null    int64  \n",
      " 9   temp        731 non-null    float64\n",
      " 10  atemp       731 non-null    float64\n",
      " 11  hum         731 non-null    float64\n",
      " 12  windspeed   731 non-null    float64\n",
      " 13  casual      731 non-null    int64  \n",
      " 14  registered  731 non-null    int64  \n",
      " 15  cnt         731 non-null    int64  \n",
      "dtypes: float64(4), int64(11), object(1)\n",
      "memory usage: 91.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting day feature from dteday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"day\"]=pd.to_datetime(df.dteday).dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.344167</td>\n",
       "      <td>0.363625</td>\n",
       "      <td>0.805833</td>\n",
       "      <td>0.160446</td>\n",
       "      <td>331</td>\n",
       "      <td>654</td>\n",
       "      <td>985</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2011-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.363478</td>\n",
       "      <td>0.353739</td>\n",
       "      <td>0.696087</td>\n",
       "      <td>0.248539</td>\n",
       "      <td>131</td>\n",
       "      <td>670</td>\n",
       "      <td>801</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2011-01-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.196364</td>\n",
       "      <td>0.189405</td>\n",
       "      <td>0.437273</td>\n",
       "      <td>0.248309</td>\n",
       "      <td>120</td>\n",
       "      <td>1229</td>\n",
       "      <td>1349</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2011-01-04</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.212122</td>\n",
       "      <td>0.590435</td>\n",
       "      <td>0.160296</td>\n",
       "      <td>108</td>\n",
       "      <td>1454</td>\n",
       "      <td>1562</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-01-05</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.226957</td>\n",
       "      <td>0.229270</td>\n",
       "      <td>0.436957</td>\n",
       "      <td>0.186900</td>\n",
       "      <td>82</td>\n",
       "      <td>1518</td>\n",
       "      <td>1600</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instant      dteday  season  yr  mnth  holiday  weekday  workingday  \\\n",
       "0        1  2011-01-01       1   0     1        0        6           0   \n",
       "1        2  2011-01-02       1   0     1        0        0           0   \n",
       "2        3  2011-01-03       1   0     1        0        1           1   \n",
       "3        4  2011-01-04       1   0     1        0        2           1   \n",
       "4        5  2011-01-05       1   0     1        0        3           1   \n",
       "\n",
       "   weathersit      temp     atemp       hum  windspeed  casual  registered  \\\n",
       "0           2  0.344167  0.363625  0.805833   0.160446     331         654   \n",
       "1           2  0.363478  0.353739  0.696087   0.248539     131         670   \n",
       "2           1  0.196364  0.189405  0.437273   0.248309     120        1229   \n",
       "3           1  0.200000  0.212122  0.590435   0.160296     108        1454   \n",
       "4           1  0.226957  0.229270  0.436957   0.186900      82        1518   \n",
       "\n",
       "    cnt  day  \n",
       "0   985    1  \n",
       "1   801    2  \n",
       "2  1349    3  \n",
       "3  1562    4  \n",
       "4  1600    5  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.344167</td>\n",
       "      <td>0.363625</td>\n",
       "      <td>0.805833</td>\n",
       "      <td>0.160446</td>\n",
       "      <td>331</td>\n",
       "      <td>654</td>\n",
       "      <td>985</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.363478</td>\n",
       "      <td>0.353739</td>\n",
       "      <td>0.696087</td>\n",
       "      <td>0.248539</td>\n",
       "      <td>131</td>\n",
       "      <td>670</td>\n",
       "      <td>801</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.196364</td>\n",
       "      <td>0.189405</td>\n",
       "      <td>0.437273</td>\n",
       "      <td>0.248309</td>\n",
       "      <td>120</td>\n",
       "      <td>1229</td>\n",
       "      <td>1349</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.212122</td>\n",
       "      <td>0.590435</td>\n",
       "      <td>0.160296</td>\n",
       "      <td>108</td>\n",
       "      <td>1454</td>\n",
       "      <td>1562</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.226957</td>\n",
       "      <td>0.229270</td>\n",
       "      <td>0.436957</td>\n",
       "      <td>0.186900</td>\n",
       "      <td>82</td>\n",
       "      <td>1518</td>\n",
       "      <td>1600</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instant  season  yr  mnth  holiday  weekday  workingday  weathersit  \\\n",
       "0        1       1   0     1        0        6           0           2   \n",
       "1        2       1   0     1        0        0           0           2   \n",
       "2        3       1   0     1        0        1           1           1   \n",
       "3        4       1   0     1        0        2           1           1   \n",
       "4        5       1   0     1        0        3           1           1   \n",
       "\n",
       "       temp     atemp       hum  windspeed  casual  registered   cnt  day  \n",
       "0  0.344167  0.363625  0.805833   0.160446     331         654   985    1  \n",
       "1  0.363478  0.353739  0.696087   0.248539     131         670   801    2  \n",
       "2  0.196364  0.189405  0.437273   0.248309     120        1229  1349    3  \n",
       "3  0.200000  0.212122  0.590435   0.160296     108        1454  1562    4  \n",
       "4  0.226957  0.229270  0.436957   0.186900      82        1518  1600    5  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(\"dteday\",1,inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for null "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "instant       0\n",
       "season        0\n",
       "yr            0\n",
       "mnth          0\n",
       "holiday       0\n",
       "weekday       0\n",
       "workingday    0\n",
       "weathersit    0\n",
       "temp          0\n",
       "atemp         0\n",
       "hum           0\n",
       "windspeed     0\n",
       "casual        0\n",
       "registered    0\n",
       "cnt           0\n",
       "day           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instant feature is unique, so we drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.344167</td>\n",
       "      <td>0.363625</td>\n",
       "      <td>0.805833</td>\n",
       "      <td>0.160446</td>\n",
       "      <td>331</td>\n",
       "      <td>654</td>\n",
       "      <td>985</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.363478</td>\n",
       "      <td>0.353739</td>\n",
       "      <td>0.696087</td>\n",
       "      <td>0.248539</td>\n",
       "      <td>131</td>\n",
       "      <td>670</td>\n",
       "      <td>801</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.196364</td>\n",
       "      <td>0.189405</td>\n",
       "      <td>0.437273</td>\n",
       "      <td>0.248309</td>\n",
       "      <td>120</td>\n",
       "      <td>1229</td>\n",
       "      <td>1349</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.212122</td>\n",
       "      <td>0.590435</td>\n",
       "      <td>0.160296</td>\n",
       "      <td>108</td>\n",
       "      <td>1454</td>\n",
       "      <td>1562</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.226957</td>\n",
       "      <td>0.229270</td>\n",
       "      <td>0.436957</td>\n",
       "      <td>0.186900</td>\n",
       "      <td>82</td>\n",
       "      <td>1518</td>\n",
       "      <td>1600</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   season  yr  mnth  holiday  weekday  workingday  weathersit      temp  \\\n",
       "0       1   0     1        0        6           0           2  0.344167   \n",
       "1       1   0     1        0        0           0           2  0.363478   \n",
       "2       1   0     1        0        1           1           1  0.196364   \n",
       "3       1   0     1        0        2           1           1  0.200000   \n",
       "4       1   0     1        0        3           1           1  0.226957   \n",
       "\n",
       "      atemp       hum  windspeed  casual  registered   cnt  day  \n",
       "0  0.363625  0.805833   0.160446     331         654   985    1  \n",
       "1  0.353739  0.696087   0.248539     131         670   801    2  \n",
       "2  0.189405  0.437273   0.248309     120        1229  1349    3  \n",
       "3  0.212122  0.590435   0.160296     108        1454  1562    4  \n",
       "4  0.229270  0.436957   0.186900      82        1518  1600    5  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(\"instant\",1,inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting some features as object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"season\"]=df[\"season\"].astype(\"object\")\n",
    "df[\"yr\"]=df[\"yr\"].astype(\"object\")\n",
    "df[\"mnth\"]=df[\"mnth\"].astype(\"object\")\n",
    "df[\"holiday\"]=df[\"holiday\"].astype(\"object\")\n",
    "df[\"weekday\"]=df[\"weekday\"].astype(\"object\")\n",
    "df[\"workingday\"]=df[\"workingday\"].astype(\"object\")\n",
    "df[\"weathersit\"]=df[\"weathersit\"].astype(\"object\")\n",
    "df[\"day\"]=df[\"day\"].astype(\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 731 entries, 0 to 730\n",
      "Data columns (total 15 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   season      731 non-null    object \n",
      " 1   yr          731 non-null    object \n",
      " 2   mnth        731 non-null    object \n",
      " 3   holiday     731 non-null    object \n",
      " 4   weekday     731 non-null    object \n",
      " 5   workingday  731 non-null    object \n",
      " 6   weathersit  731 non-null    object \n",
      " 7   temp        731 non-null    float64\n",
      " 8   atemp       731 non-null    float64\n",
      " 9   hum         731 non-null    float64\n",
      " 10  windspeed   731 non-null    float64\n",
      " 11  casual      731 non-null    int64  \n",
      " 12  registered  731 non-null    int64  \n",
      " 13  cnt         731 non-null    int64  \n",
      " 14  day         731 non-null    object \n",
      "dtypes: float64(4), int64(3), object(8)\n",
      "memory usage: 85.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X=df.drop(\"cnt\",1)\n",
    "y=df[\"cnt\"]\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_num=[\"casual\",\"registered\"]\n",
    "feat_cat=[\"season\",\"yr\",\"mnth\",\"holiday\",\"weekday\",\"workingday\",\"weathersit\",\"day\"]\n",
    "data_pipeline = ColumnTransformer([\n",
    "    ('numerical', MinMaxScaler(), feat_num),\n",
    "    ('categorical', OneHotEncoder(drop=\"first\"), feat_cat)\n",
    "    ],remainder = 'passthrough')\n",
    "\n",
    "\n",
    "\n",
    "Training_data=data_pipeline.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<411x61 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 4541 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "Validation_data=data_pipeline.transform(X_valid)\n",
    "Testing_data=data_pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(60, activation=\"relu\", input_shape=Training_data.shape[1:]),\n",
    "    \n",
    "    tf.keras.layers.Dense(30, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(10, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(5, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'scipy.sparse.csr.csr_matrix'>, <class 'NoneType'>\n",
      "Train on 411 samples, validate on 137 samples\n",
      "Epoch 1/1000\n",
      "411/411 [==============================] - 0s 517us/sample - loss: 25475386.8954 - val_loss: 22057888.4380\n",
      "Epoch 2/1000\n",
      "411/411 [==============================] - 0s 77us/sample - loss: 25470935.6983 - val_loss: 22052310.8029\n",
      "Epoch 3/1000\n",
      "411/411 [==============================] - 0s 95us/sample - loss: 25462309.2603 - val_loss: 22041283.0073\n",
      "Epoch 4/1000\n",
      "411/411 [==============================] - 0s 73us/sample - loss: 25445576.4331 - val_loss: 22019482.3066\n",
      "Epoch 5/1000\n",
      "411/411 [==============================] - 0s 78us/sample - loss: 25411832.6423 - val_loss: 21977751.3285\n",
      "Epoch 6/1000\n",
      "411/411 [==============================] - 0s 80us/sample - loss: 25348621.9562 - val_loss: 21900677.4161\n",
      "Epoch 7/1000\n",
      "411/411 [==============================] - 0s 80us/sample - loss: 25236813.5377 - val_loss: 21766854.1460\n",
      "Epoch 8/1000\n",
      "411/411 [==============================] - 0s 75us/sample - loss: 25045453.7032 - val_loss: 21549428.3212\n",
      "Epoch 9/1000\n",
      "411/411 [==============================] - 0s 75us/sample - loss: 24747498.3114 - val_loss: 21212089.7226\n",
      "Epoch 10/1000\n",
      "411/411 [==============================] - 0s 84us/sample - loss: 24296248.9294 - val_loss: 20716293.8978\n",
      "Epoch 11/1000\n",
      "411/411 [==============================] - 0s 80us/sample - loss: 23640706.8078 - val_loss: 20016081.8686\n",
      "Epoch 12/1000\n",
      "411/411 [==============================] - 0s 82us/sample - loss: 22737706.2287 - val_loss: 19060190.8248\n",
      "Epoch 13/1000\n",
      "411/411 [==============================] - 0s 83us/sample - loss: 21511446.3601 - val_loss: 17808928.2847\n",
      "Epoch 14/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 19944818.9805 - val_loss: 16226625.9635\n",
      "Epoch 15/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 17983043.1971 - val_loss: 14328383.0657\n",
      "Epoch 16/1000\n",
      "411/411 [==============================] - 0s 117us/sample - loss: 15653235.4063 - val_loss: 12156530.7153\n",
      "Epoch 17/1000\n",
      "411/411 [==============================] - 0s 92us/sample - loss: 13073558.0049 - val_loss: 9788290.7007\n",
      "Epoch 18/1000\n",
      "411/411 [==============================] - 0s 81us/sample - loss: 10330584.0912 - val_loss: 7426481.0365\n",
      "Epoch 19/1000\n",
      "411/411 [==============================] - 0s 75us/sample - loss: 7665962.4757 - val_loss: 5327365.4708\n",
      "Epoch 20/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 5311635.5779 - val_loss: 3734814.3193\n",
      "Epoch 21/1000\n",
      "411/411 [==============================] - 0s 114us/sample - loss: 3594361.3850 - val_loss: 2726389.3266\n",
      "Epoch 22/1000\n",
      "411/411 [==============================] - 0s 111us/sample - loss: 2519613.5798 - val_loss: 2298244.1273\n",
      "Epoch 23/1000\n",
      "411/411 [==============================] - 0s 111us/sample - loss: 1985959.0383 - val_loss: 2209323.9982\n",
      "Epoch 24/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 1814271.8507 - val_loss: 2222820.6788\n",
      "Epoch 25/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 1738070.5166 - val_loss: 2211974.3951\n",
      "Epoch 26/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 1691528.6533 - val_loss: 2179026.8577\n",
      "Epoch 27/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 1648262.1712 - val_loss: 2136841.6588\n",
      "Epoch 28/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 1607554.5797 - val_loss: 2096128.3321\n",
      "Epoch 29/1000\n",
      "411/411 [==============================] - 0s 113us/sample - loss: 1564622.1104 - val_loss: 2058975.8513\n",
      "Epoch 30/1000\n",
      "411/411 [==============================] - 0s 114us/sample - loss: 1527831.8625 - val_loss: 2024053.8189\n",
      "Epoch 31/1000\n",
      "411/411 [==============================] - 0s 117us/sample - loss: 1487466.2780 - val_loss: 1972763.8184\n",
      "Epoch 32/1000\n",
      "411/411 [==============================] - 0s 116us/sample - loss: 1451649.5122 - val_loss: 1944135.2682\n",
      "Epoch 33/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 1414741.2284 - val_loss: 1901598.8522\n",
      "Epoch 34/1000\n",
      "411/411 [==============================] - 0s 114us/sample - loss: 1378446.0824 - val_loss: 1875414.0474\n",
      "Epoch 35/1000\n",
      "411/411 [==============================] - 0s 114us/sample - loss: 1343608.9684 - val_loss: 1844517.3641\n",
      "Epoch 36/1000\n",
      "411/411 [==============================] - 0s 105us/sample - loss: 1308242.7570 - val_loss: 1807249.2710\n",
      "Epoch 37/1000\n",
      "411/411 [==============================] - 0s 111us/sample - loss: 1274729.8936 - val_loss: 1779083.6095\n",
      "Epoch 38/1000\n",
      "411/411 [==============================] - 0s 111us/sample - loss: 1240920.2959 - val_loss: 1740842.0420\n",
      "Epoch 39/1000\n",
      "411/411 [==============================] - 0s 108us/sample - loss: 1208267.0272 - val_loss: 1701529.2263\n",
      "Epoch 40/1000\n",
      "411/411 [==============================] - 0s 114us/sample - loss: 1176982.4048 - val_loss: 1673628.5228\n",
      "Epoch 41/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 1146014.4661 - val_loss: 1635529.4142\n",
      "Epoch 42/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 1118147.3890 - val_loss: 1613545.8786\n",
      "Epoch 43/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 1087228.8974 - val_loss: 1584634.8485\n",
      "Epoch 44/1000\n",
      "411/411 [==============================] - 0s 122us/sample - loss: 1059340.5152 - val_loss: 1541139.3266\n",
      "Epoch 45/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 1030895.0231 - val_loss: 1517076.4580\n",
      "Epoch 46/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 1003769.8634 - val_loss: 1491363.1870\n",
      "Epoch 47/1000\n",
      "411/411 [==============================] - 0s 113us/sample - loss: 978193.9602 - val_loss: 1458020.6387\n",
      "Epoch 48/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 953365.7971 - val_loss: 1436621.2518\n",
      "Epoch 49/1000\n",
      "411/411 [==============================] - 0s 90us/sample - loss: 927175.0781 - val_loss: 1409060.0949\n",
      "Epoch 50/1000\n",
      "411/411 [==============================] - 0s 94us/sample - loss: 904823.7175 - val_loss: 1373667.6387\n",
      "Epoch 51/1000\n",
      "411/411 [==============================] - 0s 80us/sample - loss: 880262.6364 - val_loss: 1354284.4078\n",
      "Epoch 52/1000\n",
      "411/411 [==============================] - 0s 87us/sample - loss: 858515.9589 - val_loss: 1331772.2391\n",
      "Epoch 53/1000\n",
      "411/411 [==============================] - 0s 75us/sample - loss: 836859.3344 - val_loss: 1294120.2865\n",
      "Epoch 54/1000\n",
      "411/411 [==============================] - 0s 83us/sample - loss: 814751.3975 - val_loss: 1273270.3682\n",
      "Epoch 55/1000\n",
      "411/411 [==============================] - 0s 85us/sample - loss: 794390.2345 - val_loss: 1250394.6793\n",
      "Epoch 56/1000\n",
      "411/411 [==============================] - 0s 82us/sample - loss: 773840.4311 - val_loss: 1224545.1396\n",
      "Epoch 57/1000\n",
      "411/411 [==============================] - 0s 115us/sample - loss: 754999.7083 - val_loss: 1200948.0219\n",
      "Epoch 58/1000\n",
      "411/411 [==============================] - 0s 118us/sample - loss: 736714.9548 - val_loss: 1181890.0693\n",
      "Epoch 59/1000\n",
      "411/411 [==============================] - 0s 111us/sample - loss: 719444.2197 - val_loss: 1151311.1542\n",
      "Epoch 60/1000\n",
      "411/411 [==============================] - 0s 110us/sample - loss: 700428.2553 - val_loss: 1135518.5557\n",
      "Epoch 61/1000\n",
      "411/411 [==============================] - 0s 109us/sample - loss: 683949.4276 - val_loss: 1115621.6971\n",
      "Epoch 62/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 667128.3498 - val_loss: 1088907.8923\n",
      "Epoch 63/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 651410.3178 - val_loss: 1069047.4640\n",
      "Epoch 64/1000\n",
      "411/411 [==============================] - 0s 106us/sample - loss: 636518.3215 - val_loss: 1045939.0639\n",
      "Epoch 65/1000\n",
      "411/411 [==============================] - 0s 109us/sample - loss: 621286.4363 - val_loss: 1024954.5520\n",
      "Epoch 66/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 606547.0712 - val_loss: 1004760.8932\n",
      "Epoch 67/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 593501.2152 - val_loss: 988490.5630\n",
      "Epoch 68/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "411/411 [==============================] - 0s 112us/sample - loss: 580185.1829 - val_loss: 966202.2128\n",
      "Epoch 69/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 567138.7860 - val_loss: 949606.7051\n",
      "Epoch 70/1000\n",
      "411/411 [==============================] - 0s 101us/sample - loss: 554557.9235 - val_loss: 932256.0029\n",
      "Epoch 71/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 543115.0017 - val_loss: 914224.0068\n",
      "Epoch 72/1000\n",
      "411/411 [==============================] - 0s 105us/sample - loss: 532535.7988 - val_loss: 902158.6214\n",
      "Epoch 73/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 520794.0519 - val_loss: 878215.4450\n",
      "Epoch 74/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 509954.5116 - val_loss: 861887.0776\n",
      "Epoch 75/1000\n",
      "411/411 [==============================] - ETA: 0s - loss: 347890.06 - 0s 100us/sample - loss: 499850.8442 - val_loss: 847921.7409\n",
      "Epoch 76/1000\n",
      "411/411 [==============================] - 0s 109us/sample - loss: 489858.7223 - val_loss: 833308.8066\n",
      "Epoch 77/1000\n",
      "411/411 [==============================] - 0s 106us/sample - loss: 480468.4132 - val_loss: 817334.9879\n",
      "Epoch 78/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 472211.6524 - val_loss: 799058.2153\n",
      "Epoch 79/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 462447.4096 - val_loss: 789070.3431\n",
      "Epoch 80/1000\n",
      "411/411 [==============================] - 0s 108us/sample - loss: 454909.0932 - val_loss: 778730.3495\n",
      "Epoch 81/1000\n",
      "411/411 [==============================] - 0s 106us/sample - loss: 446262.2380 - val_loss: 759556.2573\n",
      "Epoch 82/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 439289.1385 - val_loss: 744018.0830\n",
      "Epoch 83/1000\n",
      "411/411 [==============================] - 0s 106us/sample - loss: 431031.9558 - val_loss: 733878.2245\n",
      "Epoch 84/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 424565.6020 - val_loss: 721171.9316\n",
      "Epoch 85/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 418128.6513 - val_loss: 713588.9115\n",
      "Epoch 86/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 411277.7243 - val_loss: 696770.3574\n",
      "Epoch 87/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 404879.4127 - val_loss: 687066.4047\n",
      "Epoch 88/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 398618.4583 - val_loss: 676011.0842\n",
      "Epoch 89/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 393820.6135 - val_loss: 660024.2874\n",
      "Epoch 90/1000\n",
      "411/411 [==============================] - 0s 106us/sample - loss: 387085.0206 - val_loss: 654710.0693\n",
      "Epoch 91/1000\n",
      "411/411 [==============================] - 0s 101us/sample - loss: 381537.8242 - val_loss: 644964.5693\n",
      "Epoch 92/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 376206.2485 - val_loss: 634013.0677\n",
      "Epoch 93/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 371325.0966 - val_loss: 621541.4571\n",
      "Epoch 94/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 366631.1425 - val_loss: 613286.0212\n",
      "Epoch 95/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 362187.1743 - val_loss: 603799.2974\n",
      "Epoch 96/1000\n",
      "411/411 [==============================] - 0s 105us/sample - loss: 356989.1220 - val_loss: 598527.6720\n",
      "Epoch 97/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 353556.0759 - val_loss: 587299.9554\n",
      "Epoch 98/1000\n",
      "411/411 [==============================] - 0s 117us/sample - loss: 349035.3160 - val_loss: 577842.8634\n",
      "Epoch 99/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 344747.1334 - val_loss: 571574.7815\n",
      "Epoch 100/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 341065.9317 - val_loss: 561220.0221\n",
      "Epoch 101/1000\n",
      "411/411 [==============================] - 0s 100us/sample - loss: 336899.4028 - val_loss: 555122.5000\n",
      "Epoch 102/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 333635.3667 - val_loss: 548768.3650\n",
      "Epoch 103/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 330372.3549 - val_loss: 537672.4415\n",
      "Epoch 104/1000\n",
      "411/411 [==============================] - 0s 99us/sample - loss: 327266.8482 - val_loss: 533224.1565\n",
      "Epoch 105/1000\n",
      "411/411 [==============================] - 0s 100us/sample - loss: 323122.2327 - val_loss: 525900.1524\n",
      "Epoch 106/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 320821.3656 - val_loss: 517016.3520\n",
      "Epoch 107/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 317539.0544 - val_loss: 511384.5000\n",
      "Epoch 108/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 314098.9155 - val_loss: 507302.5717\n",
      "Epoch 109/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 312124.3587 - val_loss: 499369.6369\n",
      "Epoch 110/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 308583.3799 - val_loss: 494413.4197\n",
      "Epoch 111/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 306695.2453 - val_loss: 485398.6722\n",
      "Epoch 112/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 302770.7551 - val_loss: 481709.1925\n",
      "Epoch 113/1000\n",
      "411/411 [==============================] - 0s 99us/sample - loss: 300546.8883 - val_loss: 477252.3724\n",
      "Epoch 114/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 298317.9254 - val_loss: 470822.9589\n",
      "Epoch 115/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 296160.4781 - val_loss: 466517.2582\n",
      "Epoch 116/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 292906.7873 - val_loss: 459129.5292\n",
      "Epoch 117/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 290722.4528 - val_loss: 454780.5208\n",
      "Epoch 118/1000\n",
      "411/411 [==============================] - 0s 105us/sample - loss: 289233.9054 - val_loss: 450772.7961\n",
      "Epoch 119/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 286304.0421 - val_loss: 444445.7551\n",
      "Epoch 120/1000\n",
      "411/411 [==============================] - 0s 110us/sample - loss: 284495.9498 - val_loss: 440557.7655\n",
      "Epoch 121/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 282520.2612 - val_loss: 436256.0577\n",
      "Epoch 122/1000\n",
      "411/411 [==============================] - 0s 106us/sample - loss: 280033.8651 - val_loss: 430928.3626\n",
      "Epoch 123/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 278203.1421 - val_loss: 426254.9166\n",
      "Epoch 124/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 276512.4737 - val_loss: 424101.5849\n",
      "Epoch 125/1000\n",
      "411/411 [==============================] - 0s 120us/sample - loss: 274537.4845 - val_loss: 417734.1364\n",
      "Epoch 126/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 271931.9047 - val_loss: 415377.2972\n",
      "Epoch 127/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 269959.3695 - val_loss: 411232.2564\n",
      "Epoch 128/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 269055.2194 - val_loss: 407826.7417\n",
      "Epoch 129/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 267712.3874 - val_loss: 401570.9710\n",
      "Epoch 130/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 266903.2405 - val_loss: 400847.9438\n",
      "Epoch 131/1000\n",
      "411/411 [==============================] - 0s 99us/sample - loss: 262718.1521 - val_loss: 394313.0671\n",
      "Epoch 132/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 261044.8130 - val_loss: 391193.5544\n",
      "Epoch 133/1000\n",
      "411/411 [==============================] - 0s 103us/sample - loss: 259506.9041 - val_loss: 389169.2266\n",
      "Epoch 134/1000\n",
      "411/411 [==============================] - 0s 73us/sample - loss: 257946.9405 - val_loss: 383431.4604\n",
      "Epoch 135/1000\n",
      "411/411 [==============================] - 0s 68us/sample - loss: 255811.6304 - val_loss: 381256.1451\n",
      "Epoch 136/1000\n",
      "411/411 [==============================] - 0s 69us/sample - loss: 253953.0922 - val_loss: 377708.4935\n",
      "Epoch 137/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "411/411 [==============================] - 0s 95us/sample - loss: 252897.0534 - val_loss: 373539.3887\n",
      "Epoch 138/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 250555.0472 - val_loss: 371420.7274\n",
      "Epoch 139/1000\n",
      "411/411 [==============================] - 0s 114us/sample - loss: 248909.9708 - val_loss: 368005.9433\n",
      "Epoch 140/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 247309.5116 - val_loss: 364424.9352\n",
      "Epoch 141/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 245999.5130 - val_loss: 362210.5598\n",
      "Epoch 142/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 244181.1813 - val_loss: 358688.4498\n",
      "Epoch 143/1000\n",
      "411/411 [==============================] - 0s 106us/sample - loss: 242581.2477 - val_loss: 355160.0862\n",
      "Epoch 144/1000\n",
      "411/411 [==============================] - 0s 99us/sample - loss: 242256.0100 - val_loss: 354072.7418\n",
      "Epoch 145/1000\n",
      "411/411 [==============================] - 0s 106us/sample - loss: 239912.8525 - val_loss: 348397.5046\n",
      "Epoch 146/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 238780.9992 - val_loss: 345826.4133\n",
      "Epoch 147/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 242032.8339 - val_loss: 348624.8595\n",
      "Epoch 148/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 234864.7362 - val_loss: 340275.0785\n",
      "Epoch 149/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 234521.0904 - val_loss: 337467.4845\n",
      "Epoch 150/1000\n",
      "411/411 [==============================] - 0s 103us/sample - loss: 231581.2596 - val_loss: 336358.0133\n",
      "Epoch 151/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 230710.7143 - val_loss: 333199.4507\n",
      "Epoch 152/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 230354.5035 - val_loss: 330182.0723\n",
      "Epoch 153/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 227875.6165 - val_loss: 328436.1474\n",
      "Epoch 154/1000\n",
      "411/411 [==============================] - 0s 105us/sample - loss: 226463.8735 - val_loss: 325360.1387\n",
      "Epoch 155/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 224744.6672 - val_loss: 321909.3175\n",
      "Epoch 156/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 223619.7754 - val_loss: 319921.5464\n",
      "Epoch 157/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 222351.9182 - val_loss: 316986.8376\n",
      "Epoch 158/1000\n",
      "411/411 [==============================] - 0s 108us/sample - loss: 221435.5088 - val_loss: 316221.1661\n",
      "Epoch 159/1000\n",
      "411/411 [==============================] - 0s 105us/sample - loss: 218818.6970 - val_loss: 312257.9096\n",
      "Epoch 160/1000\n",
      "411/411 [==============================] - 0s 103us/sample - loss: 218515.8222 - val_loss: 309553.3906\n",
      "Epoch 161/1000\n",
      "411/411 [==============================] - 0s 114us/sample - loss: 217113.0156 - val_loss: 307621.8339\n",
      "Epoch 162/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 215417.1378 - val_loss: 305654.0611\n",
      "Epoch 163/1000\n",
      "411/411 [==============================] - 0s 106us/sample - loss: 214183.4199 - val_loss: 302671.8768\n",
      "Epoch 164/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 212986.5560 - val_loss: 301443.0650\n",
      "Epoch 165/1000\n",
      "411/411 [==============================] - 0s 101us/sample - loss: 211549.3580 - val_loss: 297707.1975\n",
      "Epoch 166/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 210458.1204 - val_loss: 295998.0439\n",
      "Epoch 167/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 209081.2869 - val_loss: 293938.5492\n",
      "Epoch 168/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 207126.0439 - val_loss: 292169.7026\n",
      "Epoch 169/1000\n",
      "411/411 [==============================] - 0s 99us/sample - loss: 205868.6287 - val_loss: 289372.5201\n",
      "Epoch 170/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 204423.2796 - val_loss: 287000.1820\n",
      "Epoch 171/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 203413.5186 - val_loss: 284381.1705\n",
      "Epoch 172/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 202072.5890 - val_loss: 282082.7958\n",
      "Epoch 173/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 200639.1564 - val_loss: 280717.1208\n",
      "Epoch 174/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 199984.5173 - val_loss: 278522.1564\n",
      "Epoch 175/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 198082.3769 - val_loss: 276115.0246\n",
      "Epoch 176/1000\n",
      "411/411 [==============================] - 0s 108us/sample - loss: 196853.1246 - val_loss: 274020.8378\n",
      "Epoch 177/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 195660.3212 - val_loss: 272091.4995\n",
      "Epoch 178/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 194393.7799 - val_loss: 270055.3010\n",
      "Epoch 179/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 193110.5877 - val_loss: 268065.3041\n",
      "Epoch 180/1000\n",
      "411/411 [==============================] - 0s 103us/sample - loss: 191803.0863 - val_loss: 265691.5476\n",
      "Epoch 181/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 190510.5869 - val_loss: 263999.1531\n",
      "Epoch 182/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 189464.7519 - val_loss: 261886.6095\n",
      "Epoch 183/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 187965.7780 - val_loss: 259679.4864\n",
      "Epoch 184/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 187385.1946 - val_loss: 257960.9490\n",
      "Epoch 185/1000\n",
      "411/411 [==============================] - 0s 99us/sample - loss: 185656.4141 - val_loss: 255874.6342\n",
      "Epoch 186/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 184501.0017 - val_loss: 254485.9423\n",
      "Epoch 187/1000\n",
      "411/411 [==============================] - 0s 103us/sample - loss: 183095.9584 - val_loss: 251730.3736\n",
      "Epoch 188/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 182249.5358 - val_loss: 250274.6848\n",
      "Epoch 189/1000\n",
      "411/411 [==============================] - 0s 105us/sample - loss: 181136.7478 - val_loss: 248059.3043\n",
      "Epoch 190/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 180499.9509 - val_loss: 247923.6086\n",
      "Epoch 191/1000\n",
      "411/411 [==============================] - 0s 105us/sample - loss: 178151.9448 - val_loss: 244384.7021\n",
      "Epoch 192/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 178411.3856 - val_loss: 242451.5246\n",
      "Epoch 193/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 178588.0727 - val_loss: 241124.5332\n",
      "Epoch 194/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 174453.3653 - val_loss: 238524.9632\n",
      "Epoch 195/1000\n",
      "411/411 [==============================] - 0s 97us/sample - loss: 173926.3984 - val_loss: 236983.7099\n",
      "Epoch 196/1000\n",
      "411/411 [==============================] - 0s 101us/sample - loss: 172859.7137 - val_loss: 235505.6918\n",
      "Epoch 197/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 171569.4424 - val_loss: 233321.0173\n",
      "Epoch 198/1000\n",
      "411/411 [==============================] - 0s 101us/sample - loss: 170526.0065 - val_loss: 231285.9661\n",
      "Epoch 199/1000\n",
      "411/411 [==============================] - 0s 99us/sample - loss: 169289.6413 - val_loss: 230482.9559\n",
      "Epoch 200/1000\n",
      "411/411 [==============================] - 0s 99us/sample - loss: 169087.5144 - val_loss: 227807.4986\n",
      "Epoch 201/1000\n",
      "411/411 [==============================] - 0s 111us/sample - loss: 166543.6850 - val_loss: 227280.4737\n",
      "Epoch 202/1000\n",
      "411/411 [==============================] - 0s 101us/sample - loss: 165923.9383 - val_loss: 224756.5552\n",
      "Epoch 203/1000\n",
      "411/411 [==============================] - 0s 105us/sample - loss: 164527.9454 - val_loss: 223056.6925\n",
      "Epoch 204/1000\n",
      "411/411 [==============================] - 0s 105us/sample - loss: 163840.4942 - val_loss: 221669.3295\n",
      "Epoch 205/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 162226.8558 - val_loss: 219638.3935\n",
      "Epoch 206/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "411/411 [==============================] - 0s 111us/sample - loss: 161013.6467 - val_loss: 217918.2099\n",
      "Epoch 207/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 159945.2231 - val_loss: 216429.0203\n",
      "Epoch 208/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 158933.6083 - val_loss: 214189.9954\n",
      "Epoch 209/1000\n",
      "411/411 [==============================] - 0s 101us/sample - loss: 158322.3429 - val_loss: 213524.1146\n",
      "Epoch 210/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 156928.2753 - val_loss: 211239.3609\n",
      "Epoch 211/1000\n",
      "411/411 [==============================] - 0s 105us/sample - loss: 155757.7616 - val_loss: 210092.8646\n",
      "Epoch 212/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 154532.3642 - val_loss: 207735.3433\n",
      "Epoch 213/1000\n",
      "411/411 [==============================] - 0s 103us/sample - loss: 153898.2103 - val_loss: 206432.2676\n",
      "Epoch 214/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 152022.6696 - val_loss: 205466.7461\n",
      "Epoch 215/1000\n",
      "411/411 [==============================] - ETA: 0s - loss: 126611.87 - 0s 105us/sample - loss: 151396.3545 - val_loss: 203233.9240\n",
      "Epoch 216/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 150180.0036 - val_loss: 201523.1722\n",
      "Epoch 217/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 149647.1818 - val_loss: 199894.5144\n",
      "Epoch 218/1000\n",
      "411/411 [==============================] - 0s 100us/sample - loss: 149812.4113 - val_loss: 199128.5782\n",
      "Epoch 219/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 146398.3218 - val_loss: 197006.8509\n",
      "Epoch 220/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 146278.9207 - val_loss: 195856.9685\n",
      "Epoch 221/1000\n",
      "411/411 [==============================] - 0s 100us/sample - loss: 145736.8901 - val_loss: 193772.9416\n",
      "Epoch 222/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 144467.0257 - val_loss: 193000.9630\n",
      "Epoch 223/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 142762.1859 - val_loss: 191282.0427\n",
      "Epoch 224/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 141758.2984 - val_loss: 189653.6584\n",
      "Epoch 225/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 140613.2967 - val_loss: 188032.2578\n",
      "Epoch 226/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 139683.1875 - val_loss: 186459.6569\n",
      "Epoch 227/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 139210.6596 - val_loss: 185092.9843\n",
      "Epoch 228/1000\n",
      "411/411 [==============================] - 0s 106us/sample - loss: 137369.3783 - val_loss: 183380.0965\n",
      "Epoch 229/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 136954.7893 - val_loss: 182046.2429\n",
      "Epoch 230/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 135567.0343 - val_loss: 180645.4945\n",
      "Epoch 231/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 134339.5845 - val_loss: 179287.4742\n",
      "Epoch 232/1000\n",
      "411/411 [==============================] - 0s 114us/sample - loss: 133235.2844 - val_loss: 177779.4142\n",
      "Epoch 233/1000\n",
      "411/411 [==============================] - 0s 120us/sample - loss: 132247.8863 - val_loss: 176144.7933\n",
      "Epoch 234/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 131307.2526 - val_loss: 175172.3554\n",
      "Epoch 235/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 130108.0695 - val_loss: 173295.6271\n",
      "Epoch 236/1000\n",
      "411/411 [==============================] - 0s 151us/sample - loss: 129756.5700 - val_loss: 171581.2961\n",
      "Epoch 237/1000\n",
      "411/411 [==============================] - 0s 99us/sample - loss: 128922.9396 - val_loss: 170560.3193\n",
      "Epoch 238/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 127416.3632 - val_loss: 168707.3149\n",
      "Epoch 239/1000\n",
      "411/411 [==============================] - 0s 101us/sample - loss: 126259.1394 - val_loss: 167448.4829\n",
      "Epoch 240/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 125181.2764 - val_loss: 166284.5883\n",
      "Epoch 241/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 124175.5935 - val_loss: 164730.1373\n",
      "Epoch 242/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 124059.3129 - val_loss: 163394.0042\n",
      "Epoch 243/1000\n",
      "411/411 [==============================] - 0s 101us/sample - loss: 122009.3789 - val_loss: 161940.8258\n",
      "Epoch 244/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 121439.6303 - val_loss: 160413.2006\n",
      "Epoch 245/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 121797.4341 - val_loss: 159133.3646\n",
      "Epoch 246/1000\n",
      "411/411 [==============================] - 0s 105us/sample - loss: 120971.4702 - val_loss: 158577.1986\n",
      "Epoch 247/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 118572.5153 - val_loss: 156998.6156\n",
      "Epoch 248/1000\n",
      "411/411 [==============================] - 0s 105us/sample - loss: 117876.8544 - val_loss: 154980.5863\n",
      "Epoch 249/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 116297.8713 - val_loss: 153927.7812\n",
      "Epoch 250/1000\n",
      "411/411 [==============================] - 0s 109us/sample - loss: 115354.8599 - val_loss: 152407.9447\n",
      "Epoch 251/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 114300.2643 - val_loss: 151035.6798\n",
      "Epoch 252/1000\n",
      "411/411 [==============================] - 0s 103us/sample - loss: 113610.6549 - val_loss: 149538.1511\n",
      "Epoch 253/1000\n",
      "411/411 [==============================] - ETA: 0s - loss: 112006.01 - 0s 104us/sample - loss: 112994.6299 - val_loss: 148425.1370\n",
      "Epoch 254/1000\n",
      "411/411 [==============================] - 0s 106us/sample - loss: 111365.8097 - val_loss: 146619.9023\n",
      "Epoch 255/1000\n",
      "411/411 [==============================] - 0s 109us/sample - loss: 110494.2862 - val_loss: 145349.5939\n",
      "Epoch 256/1000\n",
      "411/411 [==============================] - 0s 97us/sample - loss: 109738.5141 - val_loss: 144214.5221\n",
      "Epoch 257/1000\n",
      "411/411 [==============================] - 0s 105us/sample - loss: 108716.7306 - val_loss: 142653.4147\n",
      "Epoch 258/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 107826.5381 - val_loss: 141858.9530\n",
      "Epoch 259/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 107039.7690 - val_loss: 140397.4563\n",
      "Epoch 260/1000\n",
      "411/411 [==============================] - 0s 100us/sample - loss: 106065.4274 - val_loss: 138904.7772\n",
      "Epoch 261/1000\n",
      "411/411 [==============================] - 0s 103us/sample - loss: 105096.5140 - val_loss: 137971.1999\n",
      "Epoch 262/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 105266.3899 - val_loss: 136486.1381\n",
      "Epoch 263/1000\n",
      "411/411 [==============================] - 0s 109us/sample - loss: 103145.4761 - val_loss: 135192.7817\n",
      "Epoch 264/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 101950.9075 - val_loss: 133765.5585\n",
      "Epoch 265/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 101055.8677 - val_loss: 132867.5943\n",
      "Epoch 266/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 100246.0529 - val_loss: 131460.3582\n",
      "Epoch 267/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 99714.5208 - val_loss: 130321.6571\n",
      "Epoch 268/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 98763.2407 - val_loss: 129443.2982\n",
      "Epoch 269/1000\n",
      "411/411 [==============================] - 0s 100us/sample - loss: 97553.7673 - val_loss: 127878.0360\n",
      "Epoch 270/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 97067.0505 - val_loss: 126611.3244\n",
      "Epoch 271/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 95730.7225 - val_loss: 124989.2787\n",
      "Epoch 272/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 94730.2276 - val_loss: 123971.4197\n",
      "Epoch 273/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 93836.4427 - val_loss: 122878.3665\n",
      "Epoch 274/1000\n",
      "411/411 [==============================] - 0s 105us/sample - loss: 92855.6873 - val_loss: 121820.9086\n",
      "Epoch 275/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "411/411 [==============================] - 0s 104us/sample - loss: 91993.6200 - val_loss: 120684.3892\n",
      "Epoch 276/1000\n",
      "411/411 [==============================] - 0s 108us/sample - loss: 91366.4346 - val_loss: 119670.1440\n",
      "Epoch 277/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 91022.7993 - val_loss: 118221.0729\n",
      "Epoch 278/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 89462.9538 - val_loss: 117176.0583\n",
      "Epoch 279/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 88652.2096 - val_loss: 115666.2912\n",
      "Epoch 280/1000\n",
      "411/411 [==============================] - 0s 100us/sample - loss: 87821.6162 - val_loss: 114784.9871\n",
      "Epoch 281/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 86720.1984 - val_loss: 113712.8532\n",
      "Epoch 282/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 87075.1950 - val_loss: 112600.5766\n",
      "Epoch 283/1000\n",
      "411/411 [==============================] - 0s 119us/sample - loss: 85099.0244 - val_loss: 111932.1023\n",
      "Epoch 284/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 83742.7881 - val_loss: 110387.0373\n",
      "Epoch 285/1000\n",
      "411/411 [==============================] - 0s 86us/sample - loss: 83261.4887 - val_loss: 109145.5078\n",
      "Epoch 286/1000\n",
      "411/411 [==============================] - 0s 85us/sample - loss: 82686.8938 - val_loss: 107887.1635\n",
      "Epoch 287/1000\n",
      "411/411 [==============================] - 0s 80us/sample - loss: 81352.0059 - val_loss: 106730.6374\n",
      "Epoch 288/1000\n",
      "411/411 [==============================] - 0s 77us/sample - loss: 80854.0873 - val_loss: 105466.2706\n",
      "Epoch 289/1000\n",
      "411/411 [==============================] - 0s 75us/sample - loss: 79996.0942 - val_loss: 104282.1197\n",
      "Epoch 290/1000\n",
      "411/411 [==============================] - 0s 80us/sample - loss: 79400.9662 - val_loss: 103260.2837\n",
      "Epoch 291/1000\n",
      "411/411 [==============================] - 0s 69us/sample - loss: 78519.2163 - val_loss: 102495.6111\n",
      "Epoch 292/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 77373.1783 - val_loss: 101396.5348\n",
      "Epoch 293/1000\n",
      "411/411 [==============================] - 0s 101us/sample - loss: 76739.9791 - val_loss: 100084.4869\n",
      "Epoch 294/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 75786.1197 - val_loss: 99233.0025\n",
      "Epoch 295/1000\n",
      "411/411 [==============================] - 0s 96us/sample - loss: 74818.2122 - val_loss: 97782.1155\n",
      "Epoch 296/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 73966.1975 - val_loss: 97308.3913\n",
      "Epoch 297/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 73582.2059 - val_loss: 96083.5443\n",
      "Epoch 298/1000\n",
      "411/411 [==============================] - 0s 103us/sample - loss: 72946.5957 - val_loss: 94860.7373\n",
      "Epoch 299/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 71411.4257 - val_loss: 93630.9559\n",
      "Epoch 300/1000\n",
      "411/411 [==============================] - 0s 106us/sample - loss: 70703.8951 - val_loss: 92698.6125\n",
      "Epoch 301/1000\n",
      "411/411 [==============================] - 0s 114us/sample - loss: 70337.7031 - val_loss: 91740.2300\n",
      "Epoch 302/1000\n",
      "411/411 [==============================] - 0s 105us/sample - loss: 69251.0536 - val_loss: 90692.7414\n",
      "Epoch 303/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 68379.3736 - val_loss: 89426.7674\n",
      "Epoch 304/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 67726.8563 - val_loss: 88767.4565\n",
      "Epoch 305/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 66975.0080 - val_loss: 87322.3746\n",
      "Epoch 306/1000\n",
      "411/411 [==============================] - 0s 106us/sample - loss: 66161.1800 - val_loss: 86405.1601\n",
      "Epoch 307/1000\n",
      "411/411 [==============================] - 0s 109us/sample - loss: 65414.5445 - val_loss: 85405.2919\n",
      "Epoch 308/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 64717.9897 - val_loss: 84548.0561\n",
      "Epoch 309/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 64375.4325 - val_loss: 83840.1791\n",
      "Epoch 310/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 63590.8345 - val_loss: 82671.7972\n",
      "Epoch 311/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 62853.2479 - val_loss: 81469.3986\n",
      "Epoch 312/1000\n",
      "411/411 [==============================] - 0s 105us/sample - loss: 61674.4860 - val_loss: 80730.2095\n",
      "Epoch 313/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 60677.3141 - val_loss: 79971.8930\n",
      "Epoch 314/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 60087.2531 - val_loss: 78616.0349\n",
      "Epoch 315/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 59409.1096 - val_loss: 77805.2739\n",
      "Epoch 316/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 58542.9929 - val_loss: 76737.8633\n",
      "Epoch 317/1000\n",
      "411/411 [==============================] - 0s 97us/sample - loss: 58084.9481 - val_loss: 76124.4530\n",
      "Epoch 318/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 57111.6810 - val_loss: 75232.0965\n",
      "Epoch 319/1000\n",
      "411/411 [==============================] - 0s 109us/sample - loss: 56964.4602 - val_loss: 74135.9807\n",
      "Epoch 320/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 55971.8512 - val_loss: 73386.0611\n",
      "Epoch 321/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 56019.5647 - val_loss: 72377.7484\n",
      "Epoch 322/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 54520.8875 - val_loss: 71624.3209\n",
      "Epoch 323/1000\n",
      "411/411 [==============================] - 0s 109us/sample - loss: 53642.7568 - val_loss: 70413.7297\n",
      "Epoch 324/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 53055.1918 - val_loss: 69486.1440\n",
      "Epoch 325/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 52467.8348 - val_loss: 68690.2724\n",
      "Epoch 326/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 51582.1589 - val_loss: 67666.9306\n",
      "Epoch 327/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 51107.6104 - val_loss: 66688.1619\n",
      "Epoch 328/1000\n",
      "411/411 [==============================] - 0s 108us/sample - loss: 50726.1237 - val_loss: 66276.4793\n",
      "Epoch 329/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 49661.6165 - val_loss: 65167.5788\n",
      "Epoch 330/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 48656.3747 - val_loss: 64830.4883\n",
      "Epoch 331/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 48558.6270 - val_loss: 63627.8067\n",
      "Epoch 332/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 47459.2212 - val_loss: 63213.1104\n",
      "Epoch 333/1000\n",
      "411/411 [==============================] - 0s 101us/sample - loss: 46901.4155 - val_loss: 61860.9806\n",
      "Epoch 334/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 46365.9109 - val_loss: 60937.5956\n",
      "Epoch 335/1000\n",
      "411/411 [==============================] - 0s 103us/sample - loss: 45902.2052 - val_loss: 60024.8697\n",
      "Epoch 336/1000\n",
      "411/411 [==============================] - 0s 103us/sample - loss: 45474.4497 - val_loss: 59227.1273\n",
      "Epoch 337/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 44597.7605 - val_loss: 58842.7437\n",
      "Epoch 338/1000\n",
      "411/411 [==============================] - 0s 103us/sample - loss: 43888.1550 - val_loss: 57597.9555\n",
      "Epoch 339/1000\n",
      "411/411 [==============================] - 0s 97us/sample - loss: 43469.3469 - val_loss: 57066.3236\n",
      "Epoch 340/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 43023.5574 - val_loss: 56084.0281\n",
      "Epoch 341/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 41886.1099 - val_loss: 55743.1661\n",
      "Epoch 342/1000\n",
      "411/411 [==============================] - 0s 109us/sample - loss: 41690.1528 - val_loss: 55016.2919\n",
      "Epoch 343/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 41535.3199 - val_loss: 53989.6705\n",
      "Epoch 344/1000\n",
      "411/411 [==============================] - 0s 110us/sample - loss: 41241.4365 - val_loss: 54437.5781\n",
      "Epoch 345/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "411/411 [==============================] - 0s 102us/sample - loss: 39832.9589 - val_loss: 52462.3468\n",
      "Epoch 346/1000\n",
      "411/411 [==============================] - 0s 113us/sample - loss: 39454.8229 - val_loss: 52206.2474\n",
      "Epoch 347/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 38523.6043 - val_loss: 50934.5004\n",
      "Epoch 348/1000\n",
      "411/411 [==============================] - 0s 103us/sample - loss: 37969.0553 - val_loss: 50613.0101\n",
      "Epoch 349/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 37674.4207 - val_loss: 49451.1058\n",
      "Epoch 350/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 36981.5431 - val_loss: 48682.5758\n",
      "Epoch 351/1000\n",
      "411/411 [==============================] - 0s 97us/sample - loss: 36415.1660 - val_loss: 48328.7701\n",
      "Epoch 352/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 36178.5184 - val_loss: 47255.7772\n",
      "Epoch 353/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 35196.8199 - val_loss: 46859.3664\n",
      "Epoch 354/1000\n",
      "411/411 [==============================] - 0s 105us/sample - loss: 34737.6708 - val_loss: 46220.4891\n",
      "Epoch 355/1000\n",
      "411/411 [==============================] - 0s 109us/sample - loss: 33810.7048 - val_loss: 45125.1148\n",
      "Epoch 356/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 33310.5514 - val_loss: 45008.0801\n",
      "Epoch 357/1000\n",
      "411/411 [==============================] - 0s 100us/sample - loss: 33412.7732 - val_loss: 43777.6925\n",
      "Epoch 358/1000\n",
      "411/411 [==============================] - 0s 109us/sample - loss: 32707.6714 - val_loss: 43172.0531\n",
      "Epoch 359/1000\n",
      "411/411 [==============================] - 0s 110us/sample - loss: 31786.4429 - val_loss: 42552.1483\n",
      "Epoch 360/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 31449.3220 - val_loss: 41733.1780\n",
      "Epoch 361/1000\n",
      "411/411 [==============================] - 0s 100us/sample - loss: 31020.7456 - val_loss: 41333.3581\n",
      "Epoch 362/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 30727.8986 - val_loss: 40385.8619\n",
      "Epoch 363/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 30153.2314 - val_loss: 40267.7900\n",
      "Epoch 364/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 29307.0064 - val_loss: 39283.2861\n",
      "Epoch 365/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 28800.0053 - val_loss: 38551.6480\n",
      "Epoch 366/1000\n",
      "411/411 [==============================] - 0s 101us/sample - loss: 28486.9487 - val_loss: 37867.6006\n",
      "Epoch 367/1000\n",
      "411/411 [==============================] - 0s 111us/sample - loss: 27860.4111 - val_loss: 37333.5180\n",
      "Epoch 368/1000\n",
      "411/411 [==============================] - 0s 111us/sample - loss: 27534.7258 - val_loss: 36594.4049\n",
      "Epoch 369/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 27243.3667 - val_loss: 36650.0550\n",
      "Epoch 370/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 26279.9425 - val_loss: 35218.2000\n",
      "Epoch 371/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 25895.7161 - val_loss: 34852.7973\n",
      "Epoch 372/1000\n",
      "411/411 [==============================] - 0s 100us/sample - loss: 25308.3064 - val_loss: 34092.6538\n",
      "Epoch 373/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 24856.0262 - val_loss: 33552.0294\n",
      "Epoch 374/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 24667.1847 - val_loss: 32910.5758\n",
      "Epoch 375/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 24374.2124 - val_loss: 32699.0506\n",
      "Epoch 376/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 23869.8364 - val_loss: 31976.4396\n",
      "Epoch 377/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 23334.6227 - val_loss: 31290.4479\n",
      "Epoch 378/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 22742.7863 - val_loss: 30885.6548\n",
      "Epoch 379/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 22191.1697 - val_loss: 30261.8818\n",
      "Epoch 380/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 22002.2536 - val_loss: 30015.0780\n",
      "Epoch 381/1000\n",
      "411/411 [==============================] - 0s 111us/sample - loss: 21684.3334 - val_loss: 29120.2486\n",
      "Epoch 382/1000\n",
      "411/411 [==============================] - ETA: 0s - loss: 30549.195 - 0s 102us/sample - loss: 21052.6609 - val_loss: 28627.0673\n",
      "Epoch 383/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 20704.4595 - val_loss: 28478.8435\n",
      "Epoch 384/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 20265.6605 - val_loss: 27823.1357\n",
      "Epoch 385/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 19915.1244 - val_loss: 27283.3122\n",
      "Epoch 386/1000\n",
      "411/411 [==============================] - 0s 114us/sample - loss: 19645.8836 - val_loss: 26700.0495\n",
      "Epoch 387/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 19485.0359 - val_loss: 26984.2232\n",
      "Epoch 388/1000\n",
      "411/411 [==============================] - 0s 109us/sample - loss: 19061.0261 - val_loss: 25448.8240\n",
      "Epoch 389/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 18155.1890 - val_loss: 25153.3559\n",
      "Epoch 390/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 17531.4395 - val_loss: 24147.0426\n",
      "Epoch 391/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 17094.4007 - val_loss: 23830.0752\n",
      "Epoch 392/1000\n",
      "411/411 [==============================] - 0s 105us/sample - loss: 16949.3849 - val_loss: 23235.2029\n",
      "Epoch 393/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 16390.5121 - val_loss: 23164.9659\n",
      "Epoch 394/1000\n",
      "411/411 [==============================] - 0s 96us/sample - loss: 15828.3733 - val_loss: 22668.9460\n",
      "Epoch 395/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 15521.2370 - val_loss: 22044.9083\n",
      "Epoch 396/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 15171.5278 - val_loss: 21803.2715\n",
      "Epoch 397/1000\n",
      "411/411 [==============================] - 0s 109us/sample - loss: 14892.0797 - val_loss: 21301.1234\n",
      "Epoch 398/1000\n",
      "411/411 [==============================] - 0s 99us/sample - loss: 14531.3109 - val_loss: 21025.7133\n",
      "Epoch 399/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 14255.5612 - val_loss: 20419.1719\n",
      "Epoch 400/1000\n",
      "411/411 [==============================] - 0s 110us/sample - loss: 13973.0734 - val_loss: 20558.1820\n",
      "Epoch 401/1000\n",
      "411/411 [==============================] - 0s 106us/sample - loss: 13559.5540 - val_loss: 19681.1354\n",
      "Epoch 402/1000\n",
      "411/411 [==============================] - 0s 109us/sample - loss: 13317.4855 - val_loss: 19336.5405\n",
      "Epoch 403/1000\n",
      "411/411 [==============================] - 0s 110us/sample - loss: 12990.4879 - val_loss: 18866.3107\n",
      "Epoch 404/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 12742.7481 - val_loss: 18511.8509\n",
      "Epoch 405/1000\n",
      "411/411 [==============================] - 0s 103us/sample - loss: 12367.8656 - val_loss: 18124.2715\n",
      "Epoch 406/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 12277.9534 - val_loss: 17817.7888\n",
      "Epoch 407/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 11798.6745 - val_loss: 17638.8523\n",
      "Epoch 408/1000\n",
      "411/411 [==============================] - 0s 108us/sample - loss: 11609.0538 - val_loss: 17427.6157\n",
      "Epoch 409/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 11449.9639 - val_loss: 17031.1208\n",
      "Epoch 410/1000\n",
      "411/411 [==============================] - 0s 116us/sample - loss: 11002.3840 - val_loss: 16740.7986\n",
      "Epoch 411/1000\n",
      "411/411 [==============================] - 0s 101us/sample - loss: 10817.3940 - val_loss: 16471.4037\n",
      "Epoch 412/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 10572.1198 - val_loss: 16050.3860\n",
      "Epoch 413/1000\n",
      "411/411 [==============================] - 0s 105us/sample - loss: 10282.5493 - val_loss: 15673.3695\n",
      "Epoch 414/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 10124.8594 - val_loss: 15637.6523\n",
      "Epoch 415/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "411/411 [==============================] - 0s 102us/sample - loss: 9770.3976 - val_loss: 15038.0022\n",
      "Epoch 416/1000\n",
      "411/411 [==============================] - 0s 105us/sample - loss: 9702.8868 - val_loss: 15173.6499\n",
      "Epoch 417/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 9423.2530 - val_loss: 14607.8898\n",
      "Epoch 418/1000\n",
      "411/411 [==============================] - 0s 101us/sample - loss: 9302.3776 - val_loss: 14250.3721\n",
      "Epoch 419/1000\n",
      "411/411 [==============================] - 0s 99us/sample - loss: 9144.2308 - val_loss: 14155.3762\n",
      "Epoch 420/1000\n",
      "411/411 [==============================] - 0s 100us/sample - loss: 8694.7447 - val_loss: 13731.9005\n",
      "Epoch 421/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 8533.3683 - val_loss: 13846.9466\n",
      "Epoch 422/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 8445.7820 - val_loss: 13448.6869\n",
      "Epoch 423/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 8165.2187 - val_loss: 12849.5904\n",
      "Epoch 424/1000\n",
      "411/411 [==============================] - 0s 108us/sample - loss: 8034.5153 - val_loss: 12681.1325\n",
      "Epoch 425/1000\n",
      "411/411 [==============================] - 0s 109us/sample - loss: 7782.3175 - val_loss: 12522.7903\n",
      "Epoch 426/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 7631.1334 - val_loss: 12398.7513\n",
      "Epoch 427/1000\n",
      "411/411 [==============================] - 0s 109us/sample - loss: 7392.5361 - val_loss: 12269.1957\n",
      "Epoch 428/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 7447.4573 - val_loss: 11799.3670\n",
      "Epoch 429/1000\n",
      "411/411 [==============================] - 0s 105us/sample - loss: 7098.8826 - val_loss: 11854.1052\n",
      "Epoch 430/1000\n",
      "411/411 [==============================] - 0s 111us/sample - loss: 6994.8852 - val_loss: 11830.1983\n",
      "Epoch 431/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 7185.2021 - val_loss: 11497.6043\n",
      "Epoch 432/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 6646.9555 - val_loss: 11271.7191\n",
      "Epoch 433/1000\n",
      "411/411 [==============================] - 0s 101us/sample - loss: 6423.2618 - val_loss: 10917.2975\n",
      "Epoch 434/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 6389.9094 - val_loss: 10723.2347\n",
      "Epoch 435/1000\n",
      "411/411 [==============================] - 0s 103us/sample - loss: 6178.6805 - val_loss: 10497.6178\n",
      "Epoch 436/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 5963.2780 - val_loss: 10373.5799\n",
      "Epoch 437/1000\n",
      "411/411 [==============================] - 0s 100us/sample - loss: 5777.6797 - val_loss: 10216.9921\n",
      "Epoch 438/1000\n",
      "411/411 [==============================] - 0s 99us/sample - loss: 5740.9286 - val_loss: 10058.1358\n",
      "Epoch 439/1000\n",
      "411/411 [==============================] - 0s 109us/sample - loss: 5679.9996 - val_loss: 9745.6054\n",
      "Epoch 440/1000\n",
      "411/411 [==============================] - 0s 103us/sample - loss: 5454.6698 - val_loss: 9654.6207\n",
      "Epoch 441/1000\n",
      "411/411 [==============================] - 0s 99us/sample - loss: 5274.1975 - val_loss: 9371.9534\n",
      "Epoch 442/1000\n",
      "411/411 [==============================] - 0s 101us/sample - loss: 5392.3546 - val_loss: 9286.0068\n",
      "Epoch 443/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 5072.0837 - val_loss: 9395.0410\n",
      "Epoch 444/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 4920.7763 - val_loss: 8919.9346\n",
      "Epoch 445/1000\n",
      "411/411 [==============================] - 0s 100us/sample - loss: 4901.3883 - val_loss: 8838.4911\n",
      "Epoch 446/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 4752.7316 - val_loss: 8822.0114\n",
      "Epoch 447/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 4578.4346 - val_loss: 8607.2037\n",
      "Epoch 448/1000\n",
      "411/411 [==============================] - 0s 106us/sample - loss: 4455.1659 - val_loss: 8447.2646\n",
      "Epoch 449/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 4398.0003 - val_loss: 8325.1830\n",
      "Epoch 450/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 4329.1969 - val_loss: 8246.8541\n",
      "Epoch 451/1000\n",
      "411/411 [==============================] - 0s 108us/sample - loss: 4159.7723 - val_loss: 8069.5406\n",
      "Epoch 452/1000\n",
      "411/411 [==============================] - 0s 119us/sample - loss: 4060.4820 - val_loss: 8056.0884\n",
      "Epoch 453/1000\n",
      "411/411 [==============================] - 0s 108us/sample - loss: 4046.6500 - val_loss: 7954.9267\n",
      "Epoch 454/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 3870.2336 - val_loss: 7723.1713\n",
      "Epoch 455/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 3763.4664 - val_loss: 7578.0247\n",
      "Epoch 456/1000\n",
      "411/411 [==============================] - 0s 100us/sample - loss: 3669.5002 - val_loss: 7724.4185\n",
      "Epoch 457/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 3697.8141 - val_loss: 7399.9331\n",
      "Epoch 458/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 3548.4240 - val_loss: 7282.4447\n",
      "Epoch 459/1000\n",
      "411/411 [==============================] - 0s 103us/sample - loss: 3433.7223 - val_loss: 7225.2440\n",
      "Epoch 460/1000\n",
      "411/411 [==============================] - 0s 99us/sample - loss: 3379.5683 - val_loss: 7002.2794\n",
      "Epoch 461/1000\n",
      "411/411 [==============================] - 0s 109us/sample - loss: 3288.9624 - val_loss: 6944.1719\n",
      "Epoch 462/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 3213.4441 - val_loss: 6866.0929\n",
      "Epoch 463/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 3147.4880 - val_loss: 6852.7303\n",
      "Epoch 464/1000\n",
      "411/411 [==============================] - 0s 105us/sample - loss: 3101.9445 - val_loss: 6669.7760\n",
      "Epoch 465/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 3023.2685 - val_loss: 6704.4957\n",
      "Epoch 466/1000\n",
      "411/411 [==============================] - 0s 108us/sample - loss: 2936.5568 - val_loss: 6583.6494\n",
      "Epoch 467/1000\n",
      "411/411 [==============================] - 0s 114us/sample - loss: 2926.2916 - val_loss: 6547.4455\n",
      "Epoch 468/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 2834.7778 - val_loss: 6399.1984\n",
      "Epoch 469/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 2798.6768 - val_loss: 6685.1229\n",
      "Epoch 470/1000\n",
      "411/411 [==============================] - 0s 110us/sample - loss: 2789.5102 - val_loss: 6183.7964\n",
      "Epoch 471/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 2631.9350 - val_loss: 6190.9120\n",
      "Epoch 472/1000\n",
      "411/411 [==============================] - 0s 105us/sample - loss: 2662.7582 - val_loss: 6072.2306\n",
      "Epoch 473/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 2872.7621 - val_loss: 6333.4719\n",
      "Epoch 474/1000\n",
      "411/411 [==============================] - 0s 118us/sample - loss: 2723.9224 - val_loss: 6235.1529\n",
      "Epoch 475/1000\n",
      "411/411 [==============================] - 0s 100us/sample - loss: 2449.3983 - val_loss: 5871.6624\n",
      "Epoch 476/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 2386.2840 - val_loss: 5820.7581\n",
      "Epoch 477/1000\n",
      "411/411 [==============================] - 0s 103us/sample - loss: 2333.9822 - val_loss: 5693.6848\n",
      "Epoch 478/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 2257.0723 - val_loss: 5719.6215\n",
      "Epoch 479/1000\n",
      "411/411 [==============================] - 0s 105us/sample - loss: 2286.7443 - val_loss: 5750.3588\n",
      "Epoch 480/1000\n",
      "411/411 [==============================] - 0s 109us/sample - loss: 2241.8778 - val_loss: 5683.1838\n",
      "Epoch 481/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 2141.9177 - val_loss: 5492.6560\n",
      "Epoch 482/1000\n",
      "411/411 [==============================] - 0s 97us/sample - loss: 2095.2916 - val_loss: 5476.1290\n",
      "Epoch 483/1000\n",
      "411/411 [==============================] - 0s 111us/sample - loss: 2042.0145 - val_loss: 5338.2905\n",
      "Epoch 484/1000\n",
      "411/411 [==============================] - 0s 97us/sample - loss: 1997.4374 - val_loss: 5314.2972\n",
      "Epoch 485/1000\n",
      "411/411 [==============================] - 0s 108us/sample - loss: 2006.5624 - val_loss: 5334.4669\n",
      "Epoch 486/1000\n",
      "411/411 [==============================] - 0s 100us/sample - loss: 1947.3434 - val_loss: 5254.0987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 487/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 1924.2412 - val_loss: 5320.7412\n",
      "Epoch 488/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 1878.5550 - val_loss: 5116.0561\n",
      "Epoch 489/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 1840.0883 - val_loss: 5100.0702\n",
      "Epoch 490/1000\n",
      "411/411 [==============================] - 0s 106us/sample - loss: 1811.6595 - val_loss: 5046.3302\n",
      "Epoch 491/1000\n",
      "411/411 [==============================] - 0s 109us/sample - loss: 1759.0272 - val_loss: 4951.8368\n",
      "Epoch 492/1000\n",
      "411/411 [==============================] - 0s 106us/sample - loss: 1717.1621 - val_loss: 4984.2966\n",
      "Epoch 493/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 1679.6888 - val_loss: 4908.5273\n",
      "Epoch 494/1000\n",
      "411/411 [==============================] - 0s 158us/sample - loss: 1652.0155 - val_loss: 4850.8220\n",
      "Epoch 495/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 1618.9077 - val_loss: 4843.3847\n",
      "Epoch 496/1000\n",
      "411/411 [==============================] - 0s 111us/sample - loss: 1590.0317 - val_loss: 4712.1974\n",
      "Epoch 497/1000\n",
      "411/411 [==============================] - 0s 99us/sample - loss: 1576.1280 - val_loss: 4754.4002\n",
      "Epoch 498/1000\n",
      "411/411 [==============================] - 0s 100us/sample - loss: 1635.3928 - val_loss: 4686.7885\n",
      "Epoch 499/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 1536.4912 - val_loss: 4625.7355\n",
      "Epoch 500/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 1513.1085 - val_loss: 4553.3466\n",
      "Epoch 501/1000\n",
      "411/411 [==============================] - 0s 116us/sample - loss: 1429.3848 - val_loss: 4549.5166\n",
      "Epoch 502/1000\n",
      "411/411 [==============================] - 0s 108us/sample - loss: 1410.5241 - val_loss: 4483.0534\n",
      "Epoch 503/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 1418.6486 - val_loss: 4439.3531\n",
      "Epoch 504/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 1358.2695 - val_loss: 4423.9093\n",
      "Epoch 505/1000\n",
      "411/411 [==============================] - 0s 119us/sample - loss: 1381.7431 - val_loss: 4528.4935\n",
      "Epoch 506/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 1388.7082 - val_loss: 4462.3591\n",
      "Epoch 507/1000\n",
      "411/411 [==============================] - 0s 106us/sample - loss: 1299.1984 - val_loss: 4307.5501\n",
      "Epoch 508/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 1314.1266 - val_loss: 4274.4734\n",
      "Epoch 509/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 1300.5289 - val_loss: 4298.2785\n",
      "Epoch 510/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 1323.2211 - val_loss: 4255.6676\n",
      "Epoch 511/1000\n",
      "411/411 [==============================] - 0s 106us/sample - loss: 1236.0470 - val_loss: 4154.7925\n",
      "Epoch 512/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 1189.5620 - val_loss: 4129.3734\n",
      "Epoch 513/1000\n",
      "411/411 [==============================] - 0s 103us/sample - loss: 1183.9813 - val_loss: 4143.2045\n",
      "Epoch 514/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 1180.0765 - val_loss: 4057.5239\n",
      "Epoch 515/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 1132.9433 - val_loss: 4005.8147\n",
      "Epoch 516/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 1090.4598 - val_loss: 3944.7980\n",
      "Epoch 517/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 1089.8966 - val_loss: 3932.8981\n",
      "Epoch 518/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 1057.9717 - val_loss: 3951.8305\n",
      "Epoch 519/1000\n",
      "411/411 [==============================] - 0s 109us/sample - loss: 1078.4520 - val_loss: 3880.4861\n",
      "Epoch 520/1000\n",
      "411/411 [==============================] - 0s 103us/sample - loss: 1045.6421 - val_loss: 3850.0983\n",
      "Epoch 521/1000\n",
      "411/411 [==============================] - 0s 97us/sample - loss: 1039.2549 - val_loss: 3827.6528\n",
      "Epoch 522/1000\n",
      "411/411 [==============================] - 0s 106us/sample - loss: 1004.3794 - val_loss: 3772.5668\n",
      "Epoch 523/1000\n",
      "411/411 [==============================] - 0s 114us/sample - loss: 978.5358 - val_loss: 3725.0445\n",
      "Epoch 524/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 951.9634 - val_loss: 3726.8416\n",
      "Epoch 525/1000\n",
      "411/411 [==============================] - 0s 99us/sample - loss: 942.2152 - val_loss: 3697.4169\n",
      "Epoch 526/1000\n",
      "411/411 [==============================] - 0s 108us/sample - loss: 958.4758 - val_loss: 3640.8210\n",
      "Epoch 527/1000\n",
      "411/411 [==============================] - 0s 109us/sample - loss: 908.3730 - val_loss: 3600.2449\n",
      "Epoch 528/1000\n",
      "411/411 [==============================] - 0s 105us/sample - loss: 888.2153 - val_loss: 3574.8013\n",
      "Epoch 529/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 864.7358 - val_loss: 3563.9273\n",
      "Epoch 530/1000\n",
      "411/411 [==============================] - 0s 100us/sample - loss: 859.4371 - val_loss: 3487.2794\n",
      "Epoch 531/1000\n",
      "411/411 [==============================] - 0s 105us/sample - loss: 833.7564 - val_loss: 3483.5337\n",
      "Epoch 532/1000\n",
      "411/411 [==============================] - 0s 109us/sample - loss: 863.3859 - val_loss: 3533.7754\n",
      "Epoch 533/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 860.5011 - val_loss: 3452.2835\n",
      "Epoch 534/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 794.6953 - val_loss: 3402.5735\n",
      "Epoch 535/1000\n",
      "411/411 [==============================] - 0s 105us/sample - loss: 866.6517 - val_loss: 3380.1590\n",
      "Epoch 536/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 804.3207 - val_loss: 3328.5817\n",
      "Epoch 537/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 768.7199 - val_loss: 3321.6784\n",
      "Epoch 538/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 733.4767 - val_loss: 3283.0305\n",
      "Epoch 539/1000\n",
      "411/411 [==============================] - 0s 105us/sample - loss: 714.7311 - val_loss: 3279.7607\n",
      "Epoch 540/1000\n",
      "411/411 [==============================] - 0s 109us/sample - loss: 730.6474 - val_loss: 3310.9879\n",
      "Epoch 541/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 719.3774 - val_loss: 3232.3227\n",
      "Epoch 542/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 675.7384 - val_loss: 3174.3176\n",
      "Epoch 543/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 669.5349 - val_loss: 3156.7265\n",
      "Epoch 544/1000\n",
      "411/411 [==============================] - 0s 100us/sample - loss: 657.0892 - val_loss: 3142.2312\n",
      "Epoch 545/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 659.5794 - val_loss: 3105.9413\n",
      "Epoch 546/1000\n",
      "411/411 [==============================] - 0s 105us/sample - loss: 652.0125 - val_loss: 3096.6517\n",
      "Epoch 547/1000\n",
      "411/411 [==============================] - 0s 99us/sample - loss: 621.3914 - val_loss: 3056.0674\n",
      "Epoch 548/1000\n",
      "411/411 [==============================] - 0s 105us/sample - loss: 601.7518 - val_loss: 3041.5457\n",
      "Epoch 549/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 622.4946 - val_loss: 2995.6816\n",
      "Epoch 550/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 602.9918 - val_loss: 2983.1460\n",
      "Epoch 551/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 594.9949 - val_loss: 3004.9126\n",
      "Epoch 552/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 579.0163 - val_loss: 2914.3683\n",
      "Epoch 553/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 544.4373 - val_loss: 2918.6594\n",
      "Epoch 554/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 537.2365 - val_loss: 2895.7982\n",
      "Epoch 555/1000\n",
      "411/411 [==============================] - 0s 110us/sample - loss: 539.0906 - val_loss: 2916.7945\n",
      "Epoch 556/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 512.6514 - val_loss: 2895.3312\n",
      "Epoch 557/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 513.7086 - val_loss: 2820.5337\n",
      "Epoch 558/1000\n",
      "411/411 [==============================] - 0s 100us/sample - loss: 487.0832 - val_loss: 2793.8259\n",
      "Epoch 559/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "411/411 [==============================] - 0s 105us/sample - loss: 480.7249 - val_loss: 2794.0675\n",
      "Epoch 560/1000\n",
      "411/411 [==============================] - 0s 111us/sample - loss: 482.9117 - val_loss: 2754.9060\n",
      "Epoch 561/1000\n",
      "411/411 [==============================] - 0s 108us/sample - loss: 465.0730 - val_loss: 2713.5977\n",
      "Epoch 562/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 450.7070 - val_loss: 2713.0645\n",
      "Epoch 563/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 443.2624 - val_loss: 2700.9922\n",
      "Epoch 564/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 441.2591 - val_loss: 2718.7304\n",
      "Epoch 565/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 468.0264 - val_loss: 2686.8387\n",
      "Epoch 566/1000\n",
      "411/411 [==============================] - 0s 103us/sample - loss: 422.9152 - val_loss: 2639.9602\n",
      "Epoch 567/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 422.0900 - val_loss: 2630.6790\n",
      "Epoch 568/1000\n",
      "411/411 [==============================] - 0s 105us/sample - loss: 408.1198 - val_loss: 2610.1541\n",
      "Epoch 569/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 388.7614 - val_loss: 2615.7299\n",
      "Epoch 570/1000\n",
      "411/411 [==============================] - 0s 100us/sample - loss: 393.4362 - val_loss: 2589.9062\n",
      "Epoch 571/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 395.3642 - val_loss: 2570.2744\n",
      "Epoch 572/1000\n",
      "411/411 [==============================] - 0s 103us/sample - loss: 409.8032 - val_loss: 2617.6542\n",
      "Epoch 573/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 379.5821 - val_loss: 2522.7068\n",
      "Epoch 574/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 354.2945 - val_loss: 2505.9281\n",
      "Epoch 575/1000\n",
      "411/411 [==============================] - 0s 101us/sample - loss: 353.0253 - val_loss: 2486.4489\n",
      "Epoch 576/1000\n",
      "411/411 [==============================] - 0s 109us/sample - loss: 344.9971 - val_loss: 2442.9813\n",
      "Epoch 577/1000\n",
      "411/411 [==============================] - 0s 109us/sample - loss: 338.1140 - val_loss: 2445.1259\n",
      "Epoch 578/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 338.2502 - val_loss: 2405.7273\n",
      "Epoch 579/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 345.7947 - val_loss: 2407.3883\n",
      "Epoch 580/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 329.9976 - val_loss: 2397.5411\n",
      "Epoch 581/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 314.8835 - val_loss: 2403.2490\n",
      "Epoch 582/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 329.4663 - val_loss: 2409.3573\n",
      "Epoch 583/1000\n",
      "411/411 [==============================] - 0s 103us/sample - loss: 318.6115 - val_loss: 2341.0178\n",
      "Epoch 584/1000\n",
      "411/411 [==============================] - 0s 109us/sample - loss: 301.8111 - val_loss: 2317.7944\n",
      "Epoch 585/1000\n",
      "411/411 [==============================] - 0s 103us/sample - loss: 290.3543 - val_loss: 2366.0595\n",
      "Epoch 586/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 310.4955 - val_loss: 2317.0599\n",
      "Epoch 587/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 303.5227 - val_loss: 2278.5807\n",
      "Epoch 588/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 287.6789 - val_loss: 2266.3253\n",
      "Epoch 589/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 271.2299 - val_loss: 2255.5530\n",
      "Epoch 590/1000\n",
      "411/411 [==============================] - 0s 105us/sample - loss: 273.0270 - val_loss: 2256.3646\n",
      "Epoch 591/1000\n",
      "411/411 [==============================] - 0s 100us/sample - loss: 264.2488 - val_loss: 2238.2547\n",
      "Epoch 592/1000\n",
      "411/411 [==============================] - 0s 103us/sample - loss: 257.6816 - val_loss: 2232.8506\n",
      "Epoch 593/1000\n",
      "411/411 [==============================] - 0s 100us/sample - loss: 246.5090 - val_loss: 2234.6331\n",
      "Epoch 594/1000\n",
      "411/411 [==============================] - 0s 101us/sample - loss: 266.9282 - val_loss: 2212.4237\n",
      "Epoch 595/1000\n",
      "411/411 [==============================] - 0s 109us/sample - loss: 243.6386 - val_loss: 2191.2265\n",
      "Epoch 596/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 236.6821 - val_loss: 2186.2107\n",
      "Epoch 597/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 231.4569 - val_loss: 2142.2881\n",
      "Epoch 598/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 232.7221 - val_loss: 2148.2784\n",
      "Epoch 599/1000\n",
      "411/411 [==============================] - 0s 103us/sample - loss: 215.3576 - val_loss: 2131.0874\n",
      "Epoch 600/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 217.1407 - val_loss: 2128.8014\n",
      "Epoch 601/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 207.9117 - val_loss: 2120.0489\n",
      "Epoch 602/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 208.0241 - val_loss: 2089.8274\n",
      "Epoch 603/1000\n",
      "411/411 [==============================] - 0s 103us/sample - loss: 204.9049 - val_loss: 2080.7259\n",
      "Epoch 604/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 207.7118 - val_loss: 2068.8149\n",
      "Epoch 605/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 200.6164 - val_loss: 2074.9597\n",
      "Epoch 606/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 194.8418 - val_loss: 2034.5280\n",
      "Epoch 607/1000\n",
      "411/411 [==============================] - 0s 109us/sample - loss: 186.9780 - val_loss: 2041.6321\n",
      "Epoch 608/1000\n",
      "411/411 [==============================] - 0s 109us/sample - loss: 197.8513 - val_loss: 2036.7544\n",
      "Epoch 609/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 185.2572 - val_loss: 2039.0496\n",
      "Epoch 610/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 188.4081 - val_loss: 1993.0423\n",
      "Epoch 611/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 177.3371 - val_loss: 1981.1903\n",
      "Epoch 612/1000\n",
      "411/411 [==============================] - 0s 105us/sample - loss: 174.9098 - val_loss: 1986.9570\n",
      "Epoch 613/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 171.7719 - val_loss: 1982.3465\n",
      "Epoch 614/1000\n",
      "411/411 [==============================] - 0s 101us/sample - loss: 164.5596 - val_loss: 1960.7274\n",
      "Epoch 615/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 159.8464 - val_loss: 1945.6031\n",
      "Epoch 616/1000\n",
      "411/411 [==============================] - 0s 103us/sample - loss: 155.4381 - val_loss: 1947.7144\n",
      "Epoch 617/1000\n",
      "411/411 [==============================] - 0s 109us/sample - loss: 152.6263 - val_loss: 1931.9186\n",
      "Epoch 618/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 159.0455 - val_loss: 1931.8541\n",
      "Epoch 619/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 144.6008 - val_loss: 1944.0861\n",
      "Epoch 620/1000\n",
      "411/411 [==============================] - 0s 103us/sample - loss: 147.3009 - val_loss: 1935.9876\n",
      "Epoch 621/1000\n",
      "411/411 [==============================] - 0s 103us/sample - loss: 143.9230 - val_loss: 1885.7087\n",
      "Epoch 622/1000\n",
      "411/411 [==============================] - 0s 109us/sample - loss: 142.6205 - val_loss: 1889.8530\n",
      "Epoch 623/1000\n",
      "411/411 [==============================] - 0s 110us/sample - loss: 140.5984 - val_loss: 1899.8908\n",
      "Epoch 624/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 138.3667 - val_loss: 1851.0353\n",
      "Epoch 625/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 143.3464 - val_loss: 1854.2768\n",
      "Epoch 626/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 140.5091 - val_loss: 1889.2233\n",
      "Epoch 627/1000\n",
      "411/411 [==============================] - 0s 99us/sample - loss: 132.1322 - val_loss: 1834.5917\n",
      "Epoch 628/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 121.1499 - val_loss: 1839.4840\n",
      "Epoch 629/1000\n",
      "411/411 [==============================] - 0s 101us/sample - loss: 129.5613 - val_loss: 1859.0068\n",
      "Epoch 630/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 127.7059 - val_loss: 1822.5395\n",
      "Epoch 631/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "411/411 [==============================] - 0s 107us/sample - loss: 109.7916 - val_loss: 1817.5311\n",
      "Epoch 632/1000\n",
      "411/411 [==============================] - 0s 105us/sample - loss: 115.2183 - val_loss: 1801.7198\n",
      "Epoch 633/1000\n",
      "411/411 [==============================] - 0s 114us/sample - loss: 110.8289 - val_loss: 1767.3190\n",
      "Epoch 634/1000\n",
      "411/411 [==============================] - 0s 100us/sample - loss: 119.5061 - val_loss: 1791.2894\n",
      "Epoch 635/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 105.2653 - val_loss: 1783.3759\n",
      "Epoch 636/1000\n",
      "411/411 [==============================] - 0s 101us/sample - loss: 98.0696 - val_loss: 1767.6866\n",
      "Epoch 637/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 97.3757 - val_loss: 1747.6564\n",
      "Epoch 638/1000\n",
      "411/411 [==============================] - 0s 103us/sample - loss: 91.8043 - val_loss: 1758.7523\n",
      "Epoch 639/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 91.7520 - val_loss: 1745.0936\n",
      "Epoch 640/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 89.4068 - val_loss: 1733.4556\n",
      "Epoch 641/1000\n",
      "411/411 [==============================] - 0s 109us/sample - loss: 86.3873 - val_loss: 1761.4129\n",
      "Epoch 642/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 84.9087 - val_loss: 1726.6691\n",
      "Epoch 643/1000\n",
      "411/411 [==============================] - 0s 106us/sample - loss: 80.3301 - val_loss: 1726.8272\n",
      "Epoch 644/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 81.8888 - val_loss: 1704.5508\n",
      "Epoch 645/1000\n",
      "411/411 [==============================] - 0s 109us/sample - loss: 81.4697 - val_loss: 1719.7795\n",
      "Epoch 646/1000\n",
      "411/411 [==============================] - 0s 109us/sample - loss: 79.0018 - val_loss: 1703.1862\n",
      "Epoch 647/1000\n",
      "411/411 [==============================] - 0s 103us/sample - loss: 73.8036 - val_loss: 1685.7596\n",
      "Epoch 648/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 70.8619 - val_loss: 1693.7550\n",
      "Epoch 649/1000\n",
      "411/411 [==============================] - 0s 109us/sample - loss: 71.4315 - val_loss: 1689.6702\n",
      "Epoch 650/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 70.3863 - val_loss: 1668.2947\n",
      "Epoch 651/1000\n",
      "411/411 [==============================] - 0s 106us/sample - loss: 67.3028 - val_loss: 1673.2517\n",
      "Epoch 652/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 64.6054 - val_loss: 1688.0527\n",
      "Epoch 653/1000\n",
      "411/411 [==============================] - 0s 103us/sample - loss: 63.5499 - val_loss: 1646.8184\n",
      "Epoch 654/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 63.6055 - val_loss: 1646.1614\n",
      "Epoch 655/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 60.5130 - val_loss: 1641.7859\n",
      "Epoch 656/1000\n",
      "411/411 [==============================] - 0s 99us/sample - loss: 58.5072 - val_loss: 1636.6266\n",
      "Epoch 657/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 56.6609 - val_loss: 1628.4328\n",
      "Epoch 658/1000\n",
      "411/411 [==============================] - 0s 100us/sample - loss: 56.5494 - val_loss: 1644.6191\n",
      "Epoch 659/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 55.9340 - val_loss: 1615.4061\n",
      "Epoch 660/1000\n",
      "411/411 [==============================] - 0s 105us/sample - loss: 52.9354 - val_loss: 1617.2034\n",
      "Epoch 661/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 52.3078 - val_loss: 1608.5207\n",
      "Epoch 662/1000\n",
      "411/411 [==============================] - 0s 110us/sample - loss: 49.5548 - val_loss: 1593.5169\n",
      "Epoch 663/1000\n",
      "411/411 [==============================] - 0s 109us/sample - loss: 52.1329 - val_loss: 1618.1402\n",
      "Epoch 664/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 51.6288 - val_loss: 1575.0230\n",
      "Epoch 665/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 47.4417 - val_loss: 1598.5476\n",
      "Epoch 666/1000\n",
      "411/411 [==============================] - 0s 109us/sample - loss: 46.4048 - val_loss: 1577.3810\n",
      "Epoch 667/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 45.3364 - val_loss: 1578.9954\n",
      "Epoch 668/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 42.8280 - val_loss: 1579.1148\n",
      "Epoch 669/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 42.9970 - val_loss: 1557.4425\n",
      "Epoch 670/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 44.3326 - val_loss: 1568.2290\n",
      "Epoch 671/1000\n",
      "411/411 [==============================] - 0s 106us/sample - loss: 42.4158 - val_loss: 1543.1571\n",
      "Epoch 672/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 40.3344 - val_loss: 1553.8217\n",
      "Epoch 673/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 39.0260 - val_loss: 1562.6708\n",
      "Epoch 674/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 42.4582 - val_loss: 1524.0850\n",
      "Epoch 675/1000\n",
      "411/411 [==============================] - 0s 126us/sample - loss: 47.1336 - val_loss: 1564.9933\n",
      "Epoch 676/1000\n",
      "411/411 [==============================] - 0s 110us/sample - loss: 39.0332 - val_loss: 1517.1374\n",
      "Epoch 677/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 34.6258 - val_loss: 1536.4509\n",
      "Epoch 678/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 34.2566 - val_loss: 1527.7847\n",
      "Epoch 679/1000\n",
      "411/411 [==============================] - 0s 113us/sample - loss: 37.0308 - val_loss: 1505.3528\n",
      "Epoch 680/1000\n",
      "411/411 [==============================] - 0s 109us/sample - loss: 34.6412 - val_loss: 1533.3551\n",
      "Epoch 681/1000\n",
      "411/411 [==============================] - 0s 114us/sample - loss: 31.2561 - val_loss: 1507.8594\n",
      "Epoch 682/1000\n",
      "411/411 [==============================] - 0s 109us/sample - loss: 31.5921 - val_loss: 1517.8442\n",
      "Epoch 683/1000\n",
      "411/411 [==============================] - 0s 119us/sample - loss: 34.8017 - val_loss: 1495.0065\n",
      "Epoch 684/1000\n",
      "411/411 [==============================] - 0s 119us/sample - loss: 28.5911 - val_loss: 1497.0761\n",
      "Epoch 685/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 30.0729 - val_loss: 1490.6653\n",
      "Epoch 686/1000\n",
      "411/411 [==============================] - 0s 109us/sample - loss: 29.2853 - val_loss: 1505.0037\n",
      "Epoch 687/1000\n",
      "411/411 [==============================] - 0s 105us/sample - loss: 27.0794 - val_loss: 1500.8766\n",
      "Epoch 688/1000\n",
      "411/411 [==============================] - 0s 109us/sample - loss: 28.3263 - val_loss: 1479.4471\n",
      "Epoch 689/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 29.6223 - val_loss: 1499.6658\n",
      "Epoch 690/1000\n",
      "411/411 [==============================] - 0s 119us/sample - loss: 25.9782 - val_loss: 1484.8456\n",
      "Epoch 691/1000\n",
      "411/411 [==============================] - 0s 111us/sample - loss: 26.3600 - val_loss: 1478.3476\n",
      "Epoch 692/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 25.1043 - val_loss: 1479.0840\n",
      "Epoch 693/1000\n",
      "411/411 [==============================] - 0s 115us/sample - loss: 24.2211 - val_loss: 1490.4086\n",
      "Epoch 694/1000\n",
      "411/411 [==============================] - 0s 100us/sample - loss: 23.7581 - val_loss: 1474.9427\n",
      "Epoch 695/1000\n",
      "411/411 [==============================] - ETA: 0s - loss: 24.23 - 0s 92us/sample - loss: 23.0842 - val_loss: 1475.6306\n",
      "Epoch 696/1000\n",
      "411/411 [==============================] - 0s 90us/sample - loss: 24.2711 - val_loss: 1467.0373\n",
      "Epoch 697/1000\n",
      "411/411 [==============================] - 0s 99us/sample - loss: 21.4217 - val_loss: 1463.2883\n",
      "Epoch 698/1000\n",
      "411/411 [==============================] - 0s 115us/sample - loss: 22.4633 - val_loss: 1473.2876\n",
      "Epoch 699/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 23.2983 - val_loss: 1468.6729\n",
      "Epoch 700/1000\n",
      "411/411 [==============================] - 0s 116us/sample - loss: 22.7219 - val_loss: 1462.5804\n",
      "Epoch 701/1000\n",
      "411/411 [==============================] - 0s 109us/sample - loss: 23.5479 - val_loss: 1462.6902\n",
      "Epoch 702/1000\n",
      "411/411 [==============================] - 0s 111us/sample - loss: 20.4500 - val_loss: 1459.6613\n",
      "Epoch 703/1000\n",
      "411/411 [==============================] - 0s 114us/sample - loss: 19.6916 - val_loss: 1439.7451\n",
      "Epoch 704/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "411/411 [==============================] - 0s 119us/sample - loss: 20.9451 - val_loss: 1451.2449\n",
      "Epoch 705/1000\n",
      "411/411 [==============================] - 0s 114us/sample - loss: 19.6398 - val_loss: 1445.8354\n",
      "Epoch 706/1000\n",
      "411/411 [==============================] - 0s 120us/sample - loss: 18.9882 - val_loss: 1467.8316\n",
      "Epoch 707/1000\n",
      "411/411 [==============================] - 0s 114us/sample - loss: 18.7326 - val_loss: 1449.2458\n",
      "Epoch 708/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 18.8112 - val_loss: 1415.5409\n",
      "Epoch 709/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 18.2938 - val_loss: 1425.5440\n",
      "Epoch 710/1000\n",
      "411/411 [==============================] - 0s 106us/sample - loss: 16.2365 - val_loss: 1432.1387\n",
      "Epoch 711/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 16.3984 - val_loss: 1431.5422\n",
      "Epoch 712/1000\n",
      "411/411 [==============================] - 0s 114us/sample - loss: 15.6053 - val_loss: 1419.9641\n",
      "Epoch 713/1000\n",
      "411/411 [==============================] - 0s 116us/sample - loss: 15.4037 - val_loss: 1411.9969\n",
      "Epoch 714/1000\n",
      "411/411 [==============================] - 0s 118us/sample - loss: 18.2062 - val_loss: 1412.7197\n",
      "Epoch 715/1000\n",
      "411/411 [==============================] - 0s 114us/sample - loss: 15.9006 - val_loss: 1402.7968\n",
      "Epoch 716/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 16.4234 - val_loss: 1435.7800\n",
      "Epoch 717/1000\n",
      "411/411 [==============================] - 0s 119us/sample - loss: 16.4768 - val_loss: 1401.5740\n",
      "Epoch 718/1000\n",
      "411/411 [==============================] - 0s 111us/sample - loss: 14.7987 - val_loss: 1404.5971\n",
      "Epoch 719/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 13.7088 - val_loss: 1386.9198\n",
      "Epoch 720/1000\n",
      "411/411 [==============================] - 0s 114us/sample - loss: 13.4794 - val_loss: 1399.5413\n",
      "Epoch 721/1000\n",
      "411/411 [==============================] - 0s 124us/sample - loss: 13.2252 - val_loss: 1388.9227\n",
      "Epoch 722/1000\n",
      "411/411 [==============================] - 0s 110us/sample - loss: 12.6919 - val_loss: 1396.2144\n",
      "Epoch 723/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 12.4573 - val_loss: 1376.8069\n",
      "Epoch 724/1000\n",
      "411/411 [==============================] - 0s 113us/sample - loss: 13.5750 - val_loss: 1375.4135\n",
      "Epoch 725/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 12.6911 - val_loss: 1389.0863\n",
      "Epoch 726/1000\n",
      "411/411 [==============================] - 0s 117us/sample - loss: 12.5737 - val_loss: 1378.7298\n",
      "Epoch 727/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 12.4550 - val_loss: 1369.4852\n",
      "Epoch 728/1000\n",
      "411/411 [==============================] - 0s 111us/sample - loss: 11.9620 - val_loss: 1384.2138\n",
      "Epoch 729/1000\n",
      "411/411 [==============================] - 0s 114us/sample - loss: 12.1866 - val_loss: 1386.9986\n",
      "Epoch 730/1000\n",
      "411/411 [==============================] - 0s 116us/sample - loss: 12.5777 - val_loss: 1375.2362\n",
      "Epoch 731/1000\n",
      "411/411 [==============================] - 0s 117us/sample - loss: 11.5717 - val_loss: 1360.2290\n",
      "Epoch 732/1000\n",
      "411/411 [==============================] - 0s 111us/sample - loss: 12.3568 - val_loss: 1352.9334\n",
      "Epoch 733/1000\n",
      "411/411 [==============================] - 0s 116us/sample - loss: 10.3107 - val_loss: 1342.5031\n",
      "Epoch 734/1000\n",
      "411/411 [==============================] - 0s 163us/sample - loss: 9.7851 - val_loss: 1362.7065\n",
      "Epoch 735/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 9.7219 - val_loss: 1366.3636\n",
      "Epoch 736/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 9.8825 - val_loss: 1364.2322\n",
      "Epoch 737/1000\n",
      "411/411 [==============================] - 0s 109us/sample - loss: 10.0258 - val_loss: 1348.3084\n",
      "Epoch 738/1000\n",
      "411/411 [==============================] - 0s 119us/sample - loss: 9.9778 - val_loss: 1348.4754\n",
      "Epoch 739/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 9.1333 - val_loss: 1342.3715\n",
      "Epoch 740/1000\n",
      "411/411 [==============================] - 0s 109us/sample - loss: 8.7628 - val_loss: 1335.1195\n",
      "Epoch 741/1000\n",
      "411/411 [==============================] - 0s 111us/sample - loss: 9.1940 - val_loss: 1333.9063\n",
      "Epoch 742/1000\n",
      "411/411 [==============================] - 0s 114us/sample - loss: 8.8911 - val_loss: 1333.1061\n",
      "Epoch 743/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 8.1356 - val_loss: 1341.3203\n",
      "Epoch 744/1000\n",
      "411/411 [==============================] - 0s 113us/sample - loss: 7.9641 - val_loss: 1329.0106\n",
      "Epoch 745/1000\n",
      "411/411 [==============================] - 0s 111us/sample - loss: 7.7240 - val_loss: 1330.0018\n",
      "Epoch 746/1000\n",
      "411/411 [==============================] - 0s 127us/sample - loss: 7.8600 - val_loss: 1317.1391\n",
      "Epoch 747/1000\n",
      "411/411 [==============================] - 0s 114us/sample - loss: 7.5589 - val_loss: 1324.2377\n",
      "Epoch 748/1000\n",
      "411/411 [==============================] - 0s 111us/sample - loss: 8.1727 - val_loss: 1323.1178\n",
      "Epoch 749/1000\n",
      "411/411 [==============================] - 0s 116us/sample - loss: 9.0542 - val_loss: 1306.1744\n",
      "Epoch 750/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 8.3386 - val_loss: 1319.0121\n",
      "Epoch 751/1000\n",
      "411/411 [==============================] - 0s 110us/sample - loss: 7.2540 - val_loss: 1317.5956\n",
      "Epoch 752/1000\n",
      "411/411 [==============================] - 0s 111us/sample - loss: 6.9784 - val_loss: 1303.6818\n",
      "Epoch 753/1000\n",
      "411/411 [==============================] - 0s 109us/sample - loss: 7.0856 - val_loss: 1328.5259\n",
      "Epoch 754/1000\n",
      "411/411 [==============================] - 0s 114us/sample - loss: 6.6336 - val_loss: 1313.9071\n",
      "Epoch 755/1000\n",
      "411/411 [==============================] - 0s 121us/sample - loss: 6.4803 - val_loss: 1295.2030\n",
      "Epoch 756/1000\n",
      "411/411 [==============================] - 0s 114us/sample - loss: 6.5617 - val_loss: 1309.0572\n",
      "Epoch 757/1000\n",
      "411/411 [==============================] - 0s 109us/sample - loss: 6.7495 - val_loss: 1315.2975\n",
      "Epoch 758/1000\n",
      "411/411 [==============================] - 0s 109us/sample - loss: 8.1371 - val_loss: 1312.3298\n",
      "Epoch 759/1000\n",
      "411/411 [==============================] - 0s 109us/sample - loss: 7.3254 - val_loss: 1307.5416\n",
      "Epoch 760/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 6.4334 - val_loss: 1293.4266\n",
      "Epoch 761/1000\n",
      "411/411 [==============================] - 0s 109us/sample - loss: 6.3207 - val_loss: 1306.3861\n",
      "Epoch 762/1000\n",
      "411/411 [==============================] - 0s 106us/sample - loss: 6.3862 - val_loss: 1301.7738\n",
      "Epoch 763/1000\n",
      "411/411 [==============================] - 0s 109us/sample - loss: 5.7148 - val_loss: 1294.4333\n",
      "Epoch 764/1000\n",
      "411/411 [==============================] - 0s 99us/sample - loss: 6.1058 - val_loss: 1296.1044\n",
      "Epoch 765/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 5.6615 - val_loss: 1276.5406\n",
      "Epoch 766/1000\n",
      "411/411 [==============================] - 0s 97us/sample - loss: 6.2520 - val_loss: 1273.3962\n",
      "Epoch 767/1000\n",
      "411/411 [==============================] - 0s 109us/sample - loss: 6.7109 - val_loss: 1274.4543\n",
      "Epoch 768/1000\n",
      "411/411 [==============================] - 0s 103us/sample - loss: 5.9135 - val_loss: 1268.3027\n",
      "Epoch 769/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 5.2810 - val_loss: 1282.6866\n",
      "Epoch 770/1000\n",
      "411/411 [==============================] - 0s 97us/sample - loss: 5.2057 - val_loss: 1277.2753\n",
      "Epoch 771/1000\n",
      "411/411 [==============================] - 0s 110us/sample - loss: 5.9720 - val_loss: 1269.5177\n",
      "Epoch 772/1000\n",
      "411/411 [==============================] - 0s 109us/sample - loss: 6.5511 - val_loss: 1282.4362\n",
      "Epoch 773/1000\n",
      "411/411 [==============================] - 0s 115us/sample - loss: 5.4812 - val_loss: 1274.1923\n",
      "Epoch 774/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 5.3003 - val_loss: 1290.7059\n",
      "Epoch 775/1000\n",
      "411/411 [==============================] - 0s 115us/sample - loss: 5.3818 - val_loss: 1282.5079\n",
      "Epoch 776/1000\n",
      "411/411 [==============================] - 0s 121us/sample - loss: 5.3291 - val_loss: 1273.8179\n",
      "Epoch 777/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "411/411 [==============================] - 0s 114us/sample - loss: 5.7133 - val_loss: 1262.2293\n",
      "Epoch 778/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 5.0142 - val_loss: 1266.7214\n",
      "Epoch 779/1000\n",
      "411/411 [==============================] - 0s 105us/sample - loss: 5.3042 - val_loss: 1266.3822\n",
      "Epoch 780/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 5.5220 - val_loss: 1269.5423\n",
      "Epoch 781/1000\n",
      "411/411 [==============================] - 0s 109us/sample - loss: 4.9348 - val_loss: 1264.3713\n",
      "Epoch 782/1000\n",
      "411/411 [==============================] - ETA: 0s - loss: 2.636 - 0s 100us/sample - loss: 4.4751 - val_loss: 1268.9206\n",
      "Epoch 783/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 4.4540 - val_loss: 1262.7643\n",
      "Epoch 784/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 4.6109 - val_loss: 1251.9396\n",
      "Epoch 785/1000\n",
      "411/411 [==============================] - 0s 119us/sample - loss: 5.0444 - val_loss: 1282.8234\n",
      "Epoch 786/1000\n",
      "411/411 [==============================] - 0s 115us/sample - loss: 4.3114 - val_loss: 1261.7123\n",
      "Epoch 787/1000\n",
      "411/411 [==============================] - 0s 109us/sample - loss: 4.0823 - val_loss: 1255.3739\n",
      "Epoch 788/1000\n",
      "411/411 [==============================] - 0s 114us/sample - loss: 3.7289 - val_loss: 1264.4783\n",
      "Epoch 789/1000\n",
      "411/411 [==============================] - 0s 116us/sample - loss: 3.9487 - val_loss: 1263.1345\n",
      "Epoch 790/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 3.6425 - val_loss: 1250.7125\n",
      "Epoch 791/1000\n",
      "411/411 [==============================] - 0s 114us/sample - loss: 4.0031 - val_loss: 1262.1118\n",
      "Epoch 792/1000\n",
      "411/411 [==============================] - 0s 108us/sample - loss: 3.9118 - val_loss: 1253.9861\n",
      "Epoch 793/1000\n",
      "411/411 [==============================] - 0s 108us/sample - loss: 3.5605 - val_loss: 1247.5096\n",
      "Epoch 794/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 3.7396 - val_loss: 1253.7951\n",
      "Epoch 795/1000\n",
      "411/411 [==============================] - 0s 109us/sample - loss: 3.5594 - val_loss: 1243.7471\n",
      "Epoch 796/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 3.8320 - val_loss: 1255.8393\n",
      "Epoch 797/1000\n",
      "411/411 [==============================] - 0s 123us/sample - loss: 3.6200 - val_loss: 1237.8987\n",
      "Epoch 798/1000\n",
      "411/411 [==============================] - 0s 115us/sample - loss: 3.5005 - val_loss: 1239.3521\n",
      "Epoch 799/1000\n",
      "411/411 [==============================] - 0s 106us/sample - loss: 3.4400 - val_loss: 1240.3656\n",
      "Epoch 800/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 3.7807 - val_loss: 1248.6370\n",
      "Epoch 801/1000\n",
      "411/411 [==============================] - 0s 99us/sample - loss: 3.7744 - val_loss: 1245.4685\n",
      "Epoch 802/1000\n",
      "411/411 [==============================] - 0s 106us/sample - loss: 3.7278 - val_loss: 1234.6686\n",
      "Epoch 803/1000\n",
      "411/411 [==============================] - 0s 99us/sample - loss: 3.4275 - val_loss: 1244.8977\n",
      "Epoch 804/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 3.3403 - val_loss: 1234.6920\n",
      "Epoch 805/1000\n",
      "411/411 [==============================] - 0s 114us/sample - loss: 3.2480 - val_loss: 1234.0905\n",
      "Epoch 806/1000\n",
      "411/411 [==============================] - 0s 122us/sample - loss: 3.4792 - val_loss: 1240.0443\n",
      "Epoch 807/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 3.9198 - val_loss: 1236.7560\n",
      "Epoch 808/1000\n",
      "411/411 [==============================] - 0s 114us/sample - loss: 3.2897 - val_loss: 1234.9960\n",
      "Epoch 809/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 3.2681 - val_loss: 1234.5410\n",
      "Epoch 810/1000\n",
      "411/411 [==============================] - 0s 109us/sample - loss: 3.0655 - val_loss: 1226.1379\n",
      "Epoch 811/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 3.5166 - val_loss: 1231.7136\n",
      "Epoch 812/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 3.1406 - val_loss: 1220.2824\n",
      "Epoch 813/1000\n",
      "411/411 [==============================] - 0s 114us/sample - loss: 2.8517 - val_loss: 1225.5017\n",
      "Epoch 814/1000\n",
      "411/411 [==============================] - 0s 110us/sample - loss: 3.0005 - val_loss: 1219.0481\n",
      "Epoch 815/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 3.4643 - val_loss: 1228.5454\n",
      "Epoch 816/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 3.3117 - val_loss: 1226.1256\n",
      "Epoch 817/1000\n",
      "411/411 [==============================] - 0s 116us/sample - loss: 2.7816 - val_loss: 1228.9774\n",
      "Epoch 818/1000\n",
      "411/411 [==============================] - 0s 120us/sample - loss: 2.7629 - val_loss: 1220.5948\n",
      "Epoch 819/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 3.3161 - val_loss: 1226.2428\n",
      "Epoch 820/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 3.4813 - val_loss: 1220.0594\n",
      "Epoch 821/1000\n",
      "411/411 [==============================] - 0s 106us/sample - loss: 3.0282 - val_loss: 1211.6020\n",
      "Epoch 822/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 3.2981 - val_loss: 1237.8586\n",
      "Epoch 823/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 4.7973 - val_loss: 1212.5221\n",
      "Epoch 824/1000\n",
      "411/411 [==============================] - 0s 99us/sample - loss: 3.5172 - val_loss: 1218.2537\n",
      "Epoch 825/1000\n",
      "411/411 [==============================] - 0s 101us/sample - loss: 2.7567 - val_loss: 1212.0138\n",
      "Epoch 826/1000\n",
      "411/411 [==============================] - 0s 111us/sample - loss: 3.0586 - val_loss: 1205.6374\n",
      "Epoch 827/1000\n",
      "411/411 [==============================] - 0s 114us/sample - loss: 3.1464 - val_loss: 1206.6138\n",
      "Epoch 828/1000\n",
      "411/411 [==============================] - 0s 114us/sample - loss: 3.3253 - val_loss: 1233.5755\n",
      "Epoch 829/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 4.9922 - val_loss: 1209.9316\n",
      "Epoch 830/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 3.5889 - val_loss: 1199.9068\n",
      "Epoch 831/1000\n",
      "411/411 [==============================] - 0s 121us/sample - loss: 4.3824 - val_loss: 1222.4180\n",
      "Epoch 832/1000\n",
      "411/411 [==============================] - 0s 109us/sample - loss: 4.9323 - val_loss: 1201.1280\n",
      "Epoch 833/1000\n",
      "411/411 [==============================] - 0s 108us/sample - loss: 2.8209 - val_loss: 1212.7983\n",
      "Epoch 834/1000\n",
      "411/411 [==============================] - 0s 116us/sample - loss: 2.5465 - val_loss: 1202.1852\n",
      "Epoch 835/1000\n",
      "411/411 [==============================] - 0s 115us/sample - loss: 2.1935 - val_loss: 1214.7662\n",
      "Epoch 836/1000\n",
      "411/411 [==============================] - 0s 110us/sample - loss: 2.8130 - val_loss: 1199.2142\n",
      "Epoch 837/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 2.3010 - val_loss: 1202.5490\n",
      "Epoch 838/1000\n",
      "411/411 [==============================] - 0s 114us/sample - loss: 2.2065 - val_loss: 1200.7869\n",
      "Epoch 839/1000\n",
      "411/411 [==============================] - 0s 120us/sample - loss: 2.5838 - val_loss: 1198.8136\n",
      "Epoch 840/1000\n",
      "411/411 [==============================] - 0s 114us/sample - loss: 2.3015 - val_loss: 1203.3352\n",
      "Epoch 841/1000\n",
      "411/411 [==============================] - 0s 99us/sample - loss: 2.3814 - val_loss: 1196.8209\n",
      "Epoch 842/1000\n",
      "411/411 [==============================] - 0s 99us/sample - loss: 2.3297 - val_loss: 1191.7640\n",
      "Epoch 843/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 3.0568 - val_loss: 1192.6179\n",
      "Epoch 844/1000\n",
      "411/411 [==============================] - 0s 108us/sample - loss: 2.7032 - val_loss: 1204.3765\n",
      "Epoch 845/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 2.5398 - val_loss: 1193.2888\n",
      "Epoch 846/1000\n",
      "411/411 [==============================] - 0s 99us/sample - loss: 3.9849 - val_loss: 1208.9888\n",
      "Epoch 847/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 3.4355 - val_loss: 1193.9353\n",
      "Epoch 848/1000\n",
      "411/411 [==============================] - 0s 110us/sample - loss: 2.7584 - val_loss: 1207.4569\n",
      "Epoch 849/1000\n",
      "411/411 [==============================] - 0s 117us/sample - loss: 2.8269 - val_loss: 1194.4610\n",
      "Epoch 850/1000\n",
      "411/411 [==============================] - 0s 109us/sample - loss: 3.4789 - val_loss: 1177.6714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 851/1000\n",
      "411/411 [==============================] - 0s 114us/sample - loss: 2.4427 - val_loss: 1195.0381\n",
      "Epoch 852/1000\n",
      "411/411 [==============================] - 0s 115us/sample - loss: 2.5730 - val_loss: 1199.7556\n",
      "Epoch 853/1000\n",
      "411/411 [==============================] - 0s 114us/sample - loss: 3.1418 - val_loss: 1188.8785\n",
      "Epoch 854/1000\n",
      "411/411 [==============================] - 0s 110us/sample - loss: 2.8635 - val_loss: 1179.8825\n",
      "Epoch 855/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 2.8174 - val_loss: 1178.6786\n",
      "Epoch 856/1000\n",
      "411/411 [==============================] - 0s 110us/sample - loss: 2.6813 - val_loss: 1179.5271\n",
      "Epoch 857/1000\n",
      "411/411 [==============================] - 0s 117us/sample - loss: 2.9646 - val_loss: 1200.7903\n",
      "Epoch 858/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 3.2811 - val_loss: 1204.4161\n",
      "Epoch 859/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 3.8420 - val_loss: 1196.3733\n",
      "Epoch 860/1000\n",
      "411/411 [==============================] - 0s 117us/sample - loss: 2.9495 - val_loss: 1174.7375\n",
      "Epoch 861/1000\n",
      "411/411 [==============================] - 0s 116us/sample - loss: 3.0539 - val_loss: 1183.5215\n",
      "Epoch 862/1000\n",
      "411/411 [==============================] - 0s 111us/sample - loss: 2.4584 - val_loss: 1158.2432\n",
      "Epoch 863/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 4.4479 - val_loss: 1180.9028\n",
      "Epoch 864/1000\n",
      "411/411 [==============================] - 0s 114us/sample - loss: 6.0951 - val_loss: 1170.4628\n",
      "Epoch 865/1000\n",
      "411/411 [==============================] - 0s 117us/sample - loss: 3.3006 - val_loss: 1173.9332\n",
      "Epoch 866/1000\n",
      "411/411 [==============================] - 0s 114us/sample - loss: 2.8652 - val_loss: 1169.6745\n",
      "Epoch 867/1000\n",
      "411/411 [==============================] - 0s 114us/sample - loss: 2.8656 - val_loss: 1175.1356\n",
      "Epoch 868/1000\n",
      "411/411 [==============================] - 0s 117us/sample - loss: 5.0558 - val_loss: 1172.3221\n",
      "Epoch 869/1000\n",
      "411/411 [==============================] - 0s 124us/sample - loss: 5.1437 - val_loss: 1166.6699\n",
      "Epoch 870/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 5.3218 - val_loss: 1177.5788\n",
      "Epoch 871/1000\n",
      "411/411 [==============================] - 0s 109us/sample - loss: 3.7698 - val_loss: 1167.1405\n",
      "Epoch 872/1000\n",
      "411/411 [==============================] - 0s 113us/sample - loss: 2.8510 - val_loss: 1176.1336\n",
      "Epoch 873/1000\n",
      "411/411 [==============================] - 0s 119us/sample - loss: 2.6224 - val_loss: 1171.2940\n",
      "Epoch 874/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 2.1608 - val_loss: 1167.0289\n",
      "Epoch 875/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 3.6158 - val_loss: 1188.8724\n",
      "Epoch 876/1000\n",
      "411/411 [==============================] - 0s 114us/sample - loss: 4.2250 - val_loss: 1201.5601\n",
      "Epoch 877/1000\n",
      "411/411 [==============================] - 0s 118us/sample - loss: 2.8656 - val_loss: 1189.2120\n",
      "Epoch 878/1000\n",
      "411/411 [==============================] - 0s 114us/sample - loss: 2.6805 - val_loss: 1175.1084\n",
      "Epoch 879/1000\n",
      "411/411 [==============================] - 0s 109us/sample - loss: 2.2840 - val_loss: 1157.6278\n",
      "Epoch 880/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 3.9660 - val_loss: 1159.7410\n",
      "Epoch 881/1000\n",
      "411/411 [==============================] - 0s 102us/sample - loss: 4.5291 - val_loss: 1194.7765\n",
      "Epoch 882/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 4.9621 - val_loss: 1150.5314\n",
      "Epoch 883/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 3.7674 - val_loss: 1174.9923\n",
      "Epoch 884/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 3.1389 - val_loss: 1166.6627\n",
      "Epoch 885/1000\n",
      "411/411 [==============================] - 0s 97us/sample - loss: 2.7224 - val_loss: 1177.8964\n",
      "Epoch 886/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 2.7537 - val_loss: 1181.4447\n",
      "Epoch 887/1000\n",
      "411/411 [==============================] - 0s 105us/sample - loss: 2.3503 - val_loss: 1158.9752\n",
      "Epoch 888/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 4.3278 - val_loss: 1164.8850\n",
      "Epoch 889/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 3.3506 - val_loss: 1154.7887\n",
      "Epoch 890/1000\n",
      "411/411 [==============================] - 0s 109us/sample - loss: 3.3755 - val_loss: 1168.8299\n",
      "Epoch 891/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 2.3351 - val_loss: 1181.6881\n",
      "Epoch 892/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 4.4761 - val_loss: 1162.0642\n",
      "Epoch 893/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 2.7369 - val_loss: 1164.8917\n",
      "Epoch 894/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 2.1718 - val_loss: 1148.9549\n",
      "Epoch 895/1000\n",
      "411/411 [==============================] - 0s 116us/sample - loss: 1.8483 - val_loss: 1153.8785\n",
      "Epoch 896/1000\n",
      "411/411 [==============================] - 0s 113us/sample - loss: 1.3763 - val_loss: 1164.1100\n",
      "Epoch 897/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 2.4482 - val_loss: 1155.9333\n",
      "Epoch 898/1000\n",
      "411/411 [==============================] - 0s 111us/sample - loss: 2.8951 - val_loss: 1167.4923\n",
      "Epoch 899/1000\n",
      "411/411 [==============================] - 0s 119us/sample - loss: 3.0587 - val_loss: 1157.9284\n",
      "Epoch 900/1000\n",
      "411/411 [==============================] - 0s 115us/sample - loss: 3.2869 - val_loss: 1182.0679\n",
      "Epoch 901/1000\n",
      "411/411 [==============================] - 0s 121us/sample - loss: 2.1287 - val_loss: 1159.4154\n",
      "Epoch 902/1000\n",
      "411/411 [==============================] - 0s 118us/sample - loss: 1.9174 - val_loss: 1167.6838\n",
      "Epoch 903/1000\n",
      "411/411 [==============================] - 0s 116us/sample - loss: 2.3728 - val_loss: 1169.8343\n",
      "Epoch 904/1000\n",
      "411/411 [==============================] - 0s 117us/sample - loss: 2.6089 - val_loss: 1154.6668\n",
      "Epoch 905/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 2.4239 - val_loss: 1163.8940\n",
      "Epoch 906/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 2.3486 - val_loss: 1151.4110\n",
      "Epoch 907/1000\n",
      "411/411 [==============================] - 0s 114us/sample - loss: 2.9449 - val_loss: 1166.1018\n",
      "Epoch 908/1000\n",
      "411/411 [==============================] - 0s 113us/sample - loss: 2.5824 - val_loss: 1163.4359\n",
      "Epoch 909/1000\n",
      "411/411 [==============================] - 0s 124us/sample - loss: 3.1257 - val_loss: 1162.6747\n",
      "Epoch 910/1000\n",
      "411/411 [==============================] - 0s 113us/sample - loss: 2.3092 - val_loss: 1172.6931\n",
      "Epoch 911/1000\n",
      "411/411 [==============================] - 0s 119us/sample - loss: 2.1806 - val_loss: 1152.3398\n",
      "Epoch 912/1000\n",
      "411/411 [==============================] - 0s 114us/sample - loss: 2.2922 - val_loss: 1150.5463\n",
      "Epoch 913/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 2.8823 - val_loss: 1162.2074\n",
      "Epoch 914/1000\n",
      "411/411 [==============================] - 0s 116us/sample - loss: 3.6256 - val_loss: 1143.3082\n",
      "Epoch 915/1000\n",
      "411/411 [==============================] - 0s 116us/sample - loss: 4.3605 - val_loss: 1167.5817\n",
      "Epoch 916/1000\n",
      "411/411 [==============================] - 0s 115us/sample - loss: 3.4368 - val_loss: 1136.5379\n",
      "Epoch 917/1000\n",
      "411/411 [==============================] - 0s 124us/sample - loss: 3.6889 - val_loss: 1147.9724\n",
      "Epoch 918/1000\n",
      "411/411 [==============================] - 0s 115us/sample - loss: 2.9917 - val_loss: 1143.4696\n",
      "Epoch 919/1000\n",
      "411/411 [==============================] - 0s 114us/sample - loss: 4.5899 - val_loss: 1165.2713\n",
      "Epoch 920/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 8.7985 - val_loss: 1137.2387\n",
      "Epoch 921/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 7.8173 - val_loss: 1150.6032\n",
      "Epoch 922/1000\n",
      "411/411 [==============================] - 0s 117us/sample - loss: 4.9760 - val_loss: 1186.0532\n",
      "Epoch 923/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 3.3430 - val_loss: 1169.8320\n",
      "Epoch 924/1000\n",
      "411/411 [==============================] - 0s 119us/sample - loss: 3.1064 - val_loss: 1139.2080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 925/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 3.3983 - val_loss: 1140.6807\n",
      "Epoch 926/1000\n",
      "411/411 [==============================] - 0s 110us/sample - loss: 4.5375 - val_loss: 1165.0354\n",
      "Epoch 927/1000\n",
      "411/411 [==============================] - 0s 114us/sample - loss: 3.3225 - val_loss: 1149.4711\n",
      "Epoch 928/1000\n",
      "411/411 [==============================] - 0s 116us/sample - loss: 4.8108 - val_loss: 1149.6914\n",
      "Epoch 929/1000\n",
      "411/411 [==============================] - 0s 114us/sample - loss: 9.9011 - val_loss: 1208.6021\n",
      "Epoch 930/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 17.8814 - val_loss: 1164.8958\n",
      "Epoch 931/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 16.0246 - val_loss: 1193.4621\n",
      "Epoch 932/1000\n",
      "411/411 [==============================] - 0s 116us/sample - loss: 38.5703 - val_loss: 1224.0107\n",
      "Epoch 933/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 45.6370 - val_loss: 1115.7182\n",
      "Epoch 934/1000\n",
      "411/411 [==============================] - 0s 118us/sample - loss: 20.4552 - val_loss: 1188.3433\n",
      "Epoch 935/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 15.4857 - val_loss: 1221.1369\n",
      "Epoch 936/1000\n",
      "411/411 [==============================] - 0s 114us/sample - loss: 22.2923 - val_loss: 1187.8581\n",
      "Epoch 937/1000\n",
      "411/411 [==============================] - 0s 117us/sample - loss: 14.5503 - val_loss: 1202.3330\n",
      "Epoch 938/1000\n",
      "411/411 [==============================] - 0s 114us/sample - loss: 29.5660 - val_loss: 1167.7097\n",
      "Epoch 939/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 42.0892 - val_loss: 1170.0835\n",
      "Epoch 940/1000\n",
      "411/411 [==============================] - 0s 117us/sample - loss: 56.1113 - val_loss: 1278.0861\n",
      "Epoch 941/1000\n",
      "411/411 [==============================] - 0s 114us/sample - loss: 96.7380 - val_loss: 1383.9139\n",
      "Epoch 942/1000\n",
      "411/411 [==============================] - 0s 117us/sample - loss: 70.0640 - val_loss: 1242.8854\n",
      "Epoch 943/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 44.4690 - val_loss: 1131.3554\n",
      "Epoch 944/1000\n",
      "411/411 [==============================] - 0s 111us/sample - loss: 47.6510 - val_loss: 1184.8667\n",
      "Epoch 945/1000\n",
      "411/411 [==============================] - 0s 114us/sample - loss: 39.3508 - val_loss: 1078.6587\n",
      "Epoch 946/1000\n",
      "411/411 [==============================] - 0s 108us/sample - loss: 19.7514 - val_loss: 1148.9808\n",
      "Epoch 947/1000\n",
      "411/411 [==============================] - 0s 100us/sample - loss: 14.2382 - val_loss: 1147.8698\n",
      "Epoch 948/1000\n",
      "411/411 [==============================] - 0s 108us/sample - loss: 5.7988 - val_loss: 1168.9586\n",
      "Epoch 949/1000\n",
      "411/411 [==============================] - 0s 117us/sample - loss: 4.0630 - val_loss: 1130.6471\n",
      "Epoch 950/1000\n",
      "411/411 [==============================] - 0s 109us/sample - loss: 2.6413 - val_loss: 1166.2089\n",
      "Epoch 951/1000\n",
      "411/411 [==============================] - 0s 109us/sample - loss: 2.3361 - val_loss: 1140.2755\n",
      "Epoch 952/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 2.8871 - val_loss: 1129.2677\n",
      "Epoch 953/1000\n",
      "411/411 [==============================] - 0s 117us/sample - loss: 2.8873 - val_loss: 1152.3459\n",
      "Epoch 954/1000\n",
      "411/411 [==============================] - 0s 114us/sample - loss: 1.7579 - val_loss: 1142.8680\n",
      "Epoch 955/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 2.1977 - val_loss: 1148.6492\n",
      "Epoch 956/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 2.2506 - val_loss: 1135.4706\n",
      "Epoch 957/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 2.0576 - val_loss: 1147.8063\n",
      "Epoch 958/1000\n",
      "411/411 [==============================] - 0s 109us/sample - loss: 1.6652 - val_loss: 1170.6037\n",
      "Epoch 959/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 3.1556 - val_loss: 1156.1733\n",
      "Epoch 960/1000\n",
      "411/411 [==============================] - 0s 109us/sample - loss: 2.8336 - val_loss: 1153.1851\n",
      "Epoch 961/1000\n",
      "411/411 [==============================] - 0s 113us/sample - loss: 1.9973 - val_loss: 1161.0594\n",
      "Epoch 962/1000\n",
      "411/411 [==============================] - 0s 114us/sample - loss: 2.0958 - val_loss: 1142.8652\n",
      "Epoch 963/1000\n",
      "411/411 [==============================] - 0s 115us/sample - loss: 3.1473 - val_loss: 1130.3248\n",
      "Epoch 964/1000\n",
      "411/411 [==============================] - 0s 116us/sample - loss: 3.4661 - val_loss: 1160.0148\n",
      "Epoch 965/1000\n",
      "411/411 [==============================] - 0s 119us/sample - loss: 2.5495 - val_loss: 1135.5214\n",
      "Epoch 966/1000\n",
      "411/411 [==============================] - 0s 114us/sample - loss: 2.9458 - val_loss: 1149.8106\n",
      "Epoch 967/1000\n",
      "411/411 [==============================] - 0s 113us/sample - loss: 3.6281 - val_loss: 1165.6126\n",
      "Epoch 968/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 7.2614 - val_loss: 1109.9558\n",
      "Epoch 969/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 6.1861 - val_loss: 1155.7827\n",
      "Epoch 970/1000\n",
      "411/411 [==============================] - 0s 121us/sample - loss: 4.7275 - val_loss: 1151.9349\n",
      "Epoch 971/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 4.2885 - val_loss: 1145.8404\n",
      "Epoch 972/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 2.8422 - val_loss: 1150.1800\n",
      "Epoch 973/1000\n",
      "411/411 [==============================] - 0s 113us/sample - loss: 4.5766 - val_loss: 1162.1270\n",
      "Epoch 974/1000\n",
      "411/411 [==============================] - 0s 109us/sample - loss: 3.7228 - val_loss: 1156.5009\n",
      "Epoch 975/1000\n",
      "411/411 [==============================] - 0s 116us/sample - loss: 4.0068 - val_loss: 1159.6660\n",
      "Epoch 976/1000\n",
      "411/411 [==============================] - 0s 114us/sample - loss: 2.4880 - val_loss: 1134.7278\n",
      "Epoch 977/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 2.8204 - val_loss: 1136.8712\n",
      "Epoch 978/1000\n",
      "411/411 [==============================] - 0s 119us/sample - loss: 2.9914 - val_loss: 1145.7270\n",
      "Epoch 979/1000\n",
      "411/411 [==============================] - 0s 110us/sample - loss: 3.9027 - val_loss: 1148.3639\n",
      "Epoch 980/1000\n",
      "411/411 [==============================] - 0s 116us/sample - loss: 6.5307 - val_loss: 1143.6437\n",
      "Epoch 981/1000\n",
      "411/411 [==============================] - 0s 116us/sample - loss: 12.5230 - val_loss: 1133.0204\n",
      "Epoch 982/1000\n",
      "411/411 [==============================] - 0s 114us/sample - loss: 6.5314 - val_loss: 1132.4582\n",
      "Epoch 983/1000\n",
      "411/411 [==============================] - 0s 108us/sample - loss: 4.8734 - val_loss: 1136.8374\n",
      "Epoch 984/1000\n",
      "411/411 [==============================] - 0s 114us/sample - loss: 3.7573 - val_loss: 1138.3587\n",
      "Epoch 985/1000\n",
      "411/411 [==============================] - 0s 111us/sample - loss: 3.1403 - val_loss: 1162.1728\n",
      "Epoch 986/1000\n",
      "411/411 [==============================] - 0s 120us/sample - loss: 2.2808 - val_loss: 1127.1189\n",
      "Epoch 987/1000\n",
      "411/411 [==============================] - 0s 113us/sample - loss: 2.7148 - val_loss: 1164.8102\n",
      "Epoch 988/1000\n",
      "411/411 [==============================] - 0s 104us/sample - loss: 5.2269 - val_loss: 1144.0490\n",
      "Epoch 989/1000\n",
      "411/411 [==============================] - 0s 116us/sample - loss: 4.1991 - val_loss: 1152.6608\n",
      "Epoch 990/1000\n",
      "411/411 [==============================] - 0s 191us/sample - loss: 5.5018 - val_loss: 1135.3355\n",
      "Epoch 991/1000\n",
      "411/411 [==============================] - 0s 92us/sample - loss: 5.3063 - val_loss: 1136.7995\n",
      "Epoch 992/1000\n",
      "411/411 [==============================] - 0s 92us/sample - loss: 4.7067 - val_loss: 1129.5265\n",
      "Epoch 993/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 5.2308 - val_loss: 1169.2020\n",
      "Epoch 994/1000\n",
      "411/411 [==============================] - 0s 116us/sample - loss: 5.6980 - val_loss: 1140.8802\n",
      "Epoch 995/1000\n",
      "411/411 [==============================] - 0s 113us/sample - loss: 5.3405 - val_loss: 1150.0980\n",
      "Epoch 996/1000\n",
      "411/411 [==============================] - 0s 107us/sample - loss: 5.9194 - val_loss: 1121.5563\n",
      "Epoch 997/1000\n",
      "411/411 [==============================] - 0s 114us/sample - loss: 12.5020 - val_loss: 1140.9648\n",
      "Epoch 998/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "411/411 [==============================] - 0s 120us/sample - loss: 19.2223 - val_loss: 1149.7537\n",
      "Epoch 999/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 24.2380 - val_loss: 1200.0213\n",
      "Epoch 1000/1000\n",
      "411/411 [==============================] - 0s 112us/sample - loss: 67.4799 - val_loss: 1066.3164\n"
     ]
    }
   ],
   "source": [
    "VALIDATION_SET = (Validation_data, y_valid)\n",
    "history = model.fit(Training_data, y_train, epochs=1000,validation_data=VALIDATION_SET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'scipy.sparse.csr.csr_matrix'>, <class 'NoneType'>\n"
     ]
    }
   ],
   "source": [
    "#mse_test = model.evaluate(Testing_data, y_test)\n",
    "y_pred = model.predict(Testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting to 1_d array\n",
    "y_pred=np.squeeze(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37.13168552726431"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rmse of test data\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_test,y_pred,squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'scipy.sparse.csr.csr_matrix'>, <class 'NoneType'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6.381996547408347"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rmse of train data\n",
    "y_pred_train=np.squeeze(model.predict(Training_data))\n",
    "mean_squared_error(y_train,y_pred_train,squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
